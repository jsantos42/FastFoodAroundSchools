{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib  inline\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy\n",
    "import pandas\n",
    "import geopandas as gp\n",
    "import csv\n",
    "import shapely.geometry\n",
    "import mapclassify\n",
    "import ipywidgets\n",
    "\n",
    "pandas.options.display.max_rows = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the polygon of mainland Portugal from the map shapefile, dropping Azores and Madeira\n",
    "portugal_gdf = gp.read_file('portugal_map_shapefile/DATA/Countries/PT/NUTS_3.shp', index = False)\n",
    "azores = portugal_gdf[(portugal_gdf['NUTS_LABEL'] == 'Região Autónoma dos Açores')].index\n",
    "madeira = portugal_gdf[(portugal_gdf['NUTS_LABEL'] == 'Região Autónoma da Madeira')].index\n",
    "portugal = portugal_gdf.drop(azores.union(madeira))\n",
    "\n",
    "# Converting to the standard Coordinate Reference System of Portugal\n",
    "portugal = portugal.to_crs(EPSG=3763)\n",
    "\n",
    "# Unifying all polygons of Portugal; this will allow testing whether all the schools and \n",
    "# restaurants coordinates are within mainland Portugal\n",
    "portugal_polygon = portugal.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the polygons of the denser metropolitan areas; keeping only the relevant information\n",
    "urban_gdf = gp.read_file('portugal_map_shapefile/DATA/Countries/PT/BuiltupA.shp', index = False)\n",
    "urban = urban_gdf[['geometry']]\n",
    "\n",
    "# Converting to the standard Coordinate Reference System of Portugal\n",
    "urban = urban.to_crs(EPSG=3763)\n",
    "\n",
    "# Excluding Azores and Madeira; note that, as part of the urban polygons overflow the portugal\n",
    "# polygons, 'intersects' is a better choice than 'within'\n",
    "urban = urban[urban['geometry'].intersects(portugal_polygon) == True]\n",
    "\n",
    "# Unifying all polygons of urban\n",
    "urban_polygon = urban.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractig the points of the villages; keeping only the relevant information\n",
    "villages_gdf = gp.read_file('portugal_map_shapefile/DATA/Countries/PT/BuiltupP.shp', index = False)\n",
    "villages = villages_gdf[['NAMA1', 'geometry']].rename({'NAMA1':'Nome'}, axis = 1)\n",
    "\n",
    "# Converting to the standard Coordinate Reference System of Portugal\n",
    "villages = villages.to_crs(EPSG=3763)\n",
    "\n",
    "# Excluding Azores and Madeira\n",
    "villages = villages[villages['geometry'].within(portugal_polygon) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data from csv files\n",
    "bk_raw = pandas.read_csv('points_of_interest/burger_king.csv', sep = ';', index_col = False)\n",
    "mcd_raw = pandas.read_csv('points_of_interest/mcdonalds.csv', sep = ';', index_col = False)\n",
    "tel_raw = pandas.read_csv('points_of_interest/telepizza.csv', sep = ';', index_col = False)\n",
    "schools_raw = pandas.read_csv('points_of_interest/schools.csv', sep = ';', index_col = False)\n",
    "\n",
    "# Extracting geometric points from the coordinates\n",
    "bk_geo = [Point(xy) for xy in zip(bk_raw['Lon'], bk_raw['Lat'])]\n",
    "mcd_geo = [Point(xy) for xy in zip(mcd_raw['Lon'], mcd_raw['Lat'])]\n",
    "tel_geo = [Point(xy) for xy in zip(tel_raw['Lon'], tel_raw['Lat'])]\n",
    "schools_geo = [Point(xy) for xy in zip(schools_raw['Lon'], schools_raw['Lat'])]\n",
    "\n",
    "# Building a GeoDataFrame; note that the CRS of the raw data differs from the standard, and\n",
    "# this must be taken into account when importing\n",
    "bk_gdf = gp.GeoDataFrame(bk_raw, geometry = bk_geo, crs='EPSG:4258')\n",
    "mcd_gdf = gp.GeoDataFrame(mcd_raw, geometry = mcd_geo, crs = 'EPSG:4258')\n",
    "tel_gdf = gp.GeoDataFrame(tel_raw, geometry = tel_geo, crs = 'EPSG:4258')\n",
    "schools_gdf = gp.GeoDataFrame(schools_raw, geometry = schools_geo, crs = 'EPSG:4258')\n",
    "\n",
    "# Converting to the standard Coordinate Reference System of Portugal\n",
    "bk_crs = bk_gdf.to_crs(EPSG=3763)\n",
    "mcd_crs = mcd_gdf.to_crs(EPSG=3763)\n",
    "tel_crs = tel_gdf.to_crs(EPSG=3763)\n",
    "schools_crs = schools_gdf.to_crs(EPSG=3763)\n",
    "\n",
    "# Test for points outside Portugal (not needed anymore)\n",
    "#bk_crs[bk_crs['geometry'].within(portugal_polygon) == False]\n",
    "#mcd_crs[mcd_crs['geometry'].within(portugal_polygon) == False]\n",
    "#schools_crs[schools_crs['geometry'].within(portugal_polygon) == False]\n",
    "#tel_crs[tel_crs['geometry'].within(portugal_polygon) == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acrescentar NUT correspondente na base de dados das schools e dos restaurantes\n",
    "schools = geopandas.sjoin(portugal, schools_crs, predicate='contains', how='right')[['Nome', 'Lat', 'Lon', 'NUTS_LABEL', 'geometry']].sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "bk = geopandas.sjoin(portugal, bk_crs, predicate='contains', how='right')[['Tipo','Nome', 'Lat', 'Lon','NUTS_LABEL', 'geometry']].sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "mcd = geopandas.sjoin(portugal, mcd_crs, predicate='contains', how='right')[['Tipo','Nome', 'Lat', 'Lon','NUTS_LABEL', 'geometry']].sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "tel = geopandas.sjoin(portugal, tel_crs, predicate='contains', how='right')[['Tipo','Nome', 'Lat', 'Lon','NUTS_LABEL', 'geometry']].sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "\n",
    "#  NOTA: aqui, a referência tem que ser sempre 'right' para ir buscar as coordenadas dos pontos \n",
    "#  (e não as coordenadas dos polygons dos NUTs), pois esta operação so guarda uma geometria\n",
    "\n",
    "#criar variável com todos os 3 tipos de restaurantes\n",
    "rest = pandas.concat([mcd, bk, tel], ignore_index=True).sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# agregar schools e restaurantes por NUT para poder fazer choropleth\n",
    "schools_nut = geopandas.sjoin(portugal, schools_crs, predicate='contains', how='left')[['Nome', 'NUTS_LABEL', 'geometry']].dissolve(by='NUTS_LABEL', aggfunc='count').reset_index().rename({'Nome': 'count'}, axis=1)\n",
    "bk_nut = geopandas.sjoin(portugal, bk_crs, predicate='contains', how='left')[['Nome','NUTS_LABEL', 'geometry']].dissolve(by='NUTS_LABEL', aggfunc='count').reset_index().rename({'Nome': 'count'}, axis=1)\n",
    "mcd_nut = geopandas.sjoin(portugal, mcd_crs, predicate='contains', how='left')[['Nome', 'NUTS_LABEL', 'geometry']].dissolve(by='NUTS_LABEL', aggfunc='count').reset_index().rename({'Nome': 'count'}, axis=1)\n",
    "tel_nut = geopandas.sjoin(portugal, tel_crs, predicate='contains', how='left')[['Nome','NUTS_LABEL', 'geometry']].dissolve(by='NUTS_LABEL', aggfunc='count').reset_index().rename({'Nome': 'count'}, axis=1)\n",
    "rest_nut = geopandas.sjoin(portugal, rest.drop(columns='NUTS_LABEL'), predicate='contains', how='left')[['Nome','NUTS_LABEL', 'geometry']].dissolve(by='NUTS_LABEL', aggfunc='count').reset_index().rename({'Nome': 'count'}, axis=1)\n",
    "\n",
    "#  NOTA: aqui, a referência já tem que ser sempre 'left' para ir buscar as coordenadas dos polígonos dos NUTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirmar se há coordenadas iguais, o que há, porque schools de ensinos diferentes e, como tal, com \n",
    "# nomes diferentes podem estar no mesmo edifício\n",
    "\n",
    "#schools[schools['geometry'].duplicated(keep=False)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forma alternativa de converter df em gdf: \n",
    "#df['Coordinates']  = list(zip(df.Longitude, df.Latitude))\n",
    "#df['Coordinates'] = df['Coordinates'].apply(Point)\n",
    "#gdf = geopandas.GeoDataFrame(df, geometry='Coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grafico DEPOIS de mudar as coordenadas para UTM com unidades em metros\n",
    "fig, ax = pyplot.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
    "\n",
    "ax.set_axis_off()\n",
    "portugal.plot(ax=ax, edgecolor='k', alpha= 0.7, facecolor='white', figsize=(15,15))\n",
    "schools.plot(ax=ax, color='blue', alpha=0.5, label='schools')\n",
    "bk.plot(ax=ax, color='red', alpha= 0.2, label ='Restaurantes')\n",
    "mcd.plot(ax=ax, color='red', alpha=0.2, markersize=7)\n",
    "tel.plot(ax=ax, color='red', alpha= 0.2, markersize=7)\n",
    "ax.legend(fontsize=16,\n",
    "         loc=(-0.4, 0.5),\n",
    "         frameon=False)\n",
    "\n",
    "scalebar = ScaleBar(dx=1, length_fraction=0.4, location='lower right', color='black',sep=7, pad=0, border_pad=0)\n",
    "pyplot.gca().add_artist(scalebar)\n",
    "\n",
    "\n",
    "\n",
    "#pp.title('urban', fontweight='bold')\n",
    "\n",
    "\n",
    "\n",
    "#tirar os eixos mas manter um background cor diferente\n",
    "#ax.set_facecolor((0, 0, 0, 0.05))\n",
    "#ax.set_axis_off()\n",
    "#ax.add_artist(ax.patch)\n",
    "#ax.patch.set_zorder(-1)\n",
    "\n",
    "\n",
    "\n",
    "#grafico1.set(xlim=(-100000, -80000), ylim=(-115000,-95000)) #lisboa \n",
    "\n",
    "\n",
    "#grafico1.set(xlim=(-150000, 170000), ylim=(-310000,285000))\n",
    "#grafico1.set(xlim=(-130000, -55000), ylim=(-150000,-50000)) #lisboa \n",
    "#grafico1.set(xlim=(-60000, 0), ylim=(140000,180000)) #porto\n",
    "\n",
    "#teste pontos\n",
    "#grafico1.set(xlim=(-60000, 0), ylim=(90000,180000))\n",
    "#schools.loc[[0], 'geometry'].plot(ax=grafico1, color='blue', alpha=1, markersize=15)\n",
    "#rest.loc[[1], 'geometry'].plot(ax=grafico1, color='black', alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
    "\n",
    "ax.set_axis_off()\n",
    "portugal.plot(ax=ax, edgecolor='k', alpha= 0.7, facecolor='white', figsize=(15,15))\n",
    "urban.plot(ax=ax, color='red', alpha=0.8)\n",
    "\n",
    "#Not all handles can be turned into legend entries automatically, so it is often necessary to create an artist which can\n",
    "#ver em https://matplotlib.org/tutorials/intermediate/legend_guide.html\n",
    "red_patch = mpatches.Patch(color='red', label='urban')\n",
    "\n",
    "\n",
    "ax.legend(handles=[red_patch],\n",
    "          fontsize=16,\n",
    "         loc=(-0.4, 0.5),\n",
    "         frameon=False)\n",
    "\n",
    "scalebar = ScaleBar(dx=1, length_fraction=0.4, location='lower right', color='black',sep=7, pad=0, border_pad=0)\n",
    "pyplot.gca().add_artist(scalebar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
    "\n",
    "ax.set_axis_off()\n",
    "portugal.plot(ax=ax, edgecolor='k', alpha= 0.7, facecolor='white', figsize=(15,15))\n",
    "villages.plot(ax=ax, color='crimson', facecolor='none', label='Vilas')\n",
    "ax.legend(fontsize=20,\n",
    "         loc=(-0.4, 0.5),\n",
    "         frameon=False)\n",
    "\n",
    "scalebar = ScaleBar(dx=1, length_fraction=0.4, location='lower right', color='black',sep=7, pad=0, border_pad=0)\n",
    "pyplot.gca().add_artist(scalebar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribuiçao nacional das schools e de cada restaurante, por NUT\n",
    "fig, (g2, g3, g4, g5, g6) = pyplot.subplots(nrows=1, ncols=5, figsize=(20, 16))\n",
    "pyplot.tight_layout()\n",
    "\n",
    "grafico2 = schools_nut.plot(ax=g2, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico3 = bk_nut.plot(ax=g3, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico4 = mcd_nut.plot(ax=g4, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico5 = tel_nut.plot(ax=g5, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico6 = rest_nut.plot(ax=g6, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1></h1>\n",
    "<h1>OBJECTIVO 1</h1>\n",
    "<h2>Determinar, para cada escola em Portugal continental, qual a proximidade ao estabelecimento de fast-food (EFF) mais próximo</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mudei os nomes das entradas para Capitalized\n",
    "#acrescentei o tipo de rest nos csv dos mcd e tel\n",
    "#padronizei os labels das colunas\n",
    "#comparei visualmente no mapa para ver se batia certo\n",
    "\n",
    "\n",
    "#retirado de https://gis.stackexchange.com/questions/222315/geopandas-find-nearest-point-in-other-dataframe\n",
    "\n",
    "def ckdnearest(gdA, gdB):\n",
    "    nA = numpy.array(list(gdA.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    nB = numpy.array(list(gdB.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    btree = cKDTree(nB)\n",
    "    dist, idx = btree.query(nA, k=1)\n",
    "    gdf = pandas.concat(\n",
    "        [gdA.reset_index(drop=True), gdB.loc[idx, gdB.columns != 'geometry'].reset_index(drop=True),\n",
    "         pandas.Series(dist, name='dist')], axis=1)\n",
    "    gdf['dist'] = gdf['dist'] / 1000  #conversao de m para km\n",
    "    return gdf\n",
    "\n",
    "prox = ckdnearest(schools.drop(columns=['Lat', 'Lon']).rename({'Nome':'ESCOLA'}, axis =1), rest.drop(columns=['Lat', 'Lon', 'NUTS_LABEL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar schools e restaurantes por NUT para poder fazer choropleth\n",
    "# criar as estatisticas por NUTs\n",
    "\n",
    "prox_mean = geopandas.sjoin(portugal, prox.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','ESCOLA','Nome','dist']].dissolve(by='NUTS_LABEL', aggfunc='mean').reset_index().rename({'dist': 'mean'}, axis=1)\n",
    "prox_median = geopandas.sjoin(portugal, prox.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','ESCOLA','Nome','dist']].dissolve(by='NUTS_LABEL', aggfunc='median').reset_index().rename({'dist': 'median'}, axis=1)\n",
    "prox_min = geopandas.sjoin(portugal, prox.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','dist']].dissolve(by='NUTS_LABEL', aggfunc='min').reset_index().rename({'dist': 'min'}, axis=1)\n",
    "prox_max = geopandas.sjoin(portugal, prox.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','dist']].dissolve(by='NUTS_LABEL', aggfunc='max').reset_index().rename({'dist': 'max'}, axis=1)\n",
    "\n",
    "prox_nut = prox_mean.merge(prox_min.drop(columns='geometry'), on='NUTS_LABEL').merge(prox_median.drop(columns='geometry'), on='NUTS_LABEL').merge(prox_max.drop(columns='geometry'), on='NUTS_LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_nut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact\n",
    "def show_articles_more_than(column=['median', 'min'], x=(0, 35, 1)):\n",
    "    return prox_nut.loc[prox_nut[column] < x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, (g7, g8, g9) = pyplot.subplots(nrows=1, ncols=3, figsize=(20, 16))\n",
    "#usamos a mediana pois ha outliers\n",
    "pyplot.tight_layout()\n",
    "\n",
    "grafico7 = prox_nut.plot(column='median', figsize=(20,16), legend=True, scheme='FisherJenks', cmap='Greens_r', edgecolor='k')\n",
    "grafico7.set_axis_off()\n",
    "#grafico8 = prox_nut.plot(ax=g8, column='min', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens_r', edgecolor='k')\n",
    "#grafico9 = prox_nut.plot(ax=g9, column='max', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens_r', edgecolor='k')\n",
    "#fig.canvas.toolbar_visible = False\n",
    "#fig.canvas.header_visible = False\n",
    "#fig.canvas.resizable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.distplot(prox_nut['min'], rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1></h1>\n",
    "<h1>OBJECTIVO 2</h1>\n",
    "<h2>Determinar, para cada escola em Portugal continental, quantos EFF estão a curta distância (raios de 5 e de 10min a pé)</h2>\n",
    "<h1>SEEMS TO BE WORKING UNTIL HERE</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada escola, criar um raio de 400m e de 800m e contar quantos rest estão nesse círculos\n",
    "i = 0\n",
    "raio = schools[:]  # slice op para copiar o conteúdo e não linkar à variável antiga\n",
    "raio['400m'] = ''  # criar novas duas colunas vazias\n",
    "raio['800m'] = ''\n",
    "\n",
    "for i in range(len(schools)):\n",
    "    raio.loc[i,'400m'] = len(rest[rest['geometry'].within(schools['geometry'][i].buffer(400))])\n",
    "    raio.loc[i,'800m'] = len(rest[rest['geometry'].within(schools['geometry'][i].buffer(800))])\n",
    "\n",
    "raio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar dados raio por NUT para poder fazer choropleth\n",
    "# soma\n",
    "raio_nut = geopandas.sjoin(portugal, raio.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','Nome','400m','800m']].dissolve(by='NUTS_LABEL', aggfunc='sum').reset_index()\n",
    "\n",
    "\n",
    "# média de restaurantes no raio especificado para as schools de cada NUT\n",
    "raio_mean = geopandas.sjoin(portugal, raio.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','400m','800m']]\n",
    "raio_mean[['400m', '800m']] = raio_mean[['400m', '800m']].apply(pandas.to_numeric) # por algum motivo que desconheço, estas colunas aparecem como objectos e impossibilitam a obtenção da média, pelo que tenho de converter em números\n",
    "raio_mean = raio_mean.dissolve(by='NUTS_LABEL', aggfunc='mean').reset_index().rename({'400m': '400m_mean', '800m': '800m_mean'}, axis=1)\n",
    "\n",
    "#juntar\n",
    "raio_nut = raio_nut.merge(raio_mean.drop(columns=['geometry']), on='NUTS_LABEL')\n",
    "raio_nut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (g12, g13) = pp.subplots(nrows=1, ncols=2, figsize=(20, 16))\n",
    "#fig, (g10, g11, g12, g13) = pp.subplots(nrows=1, ncols=4, figsize=(20, 16))\n",
    "pp.tight_layout()\n",
    "\n",
    "#grafico10 = raio_nut.plot(ax=g10, column='400m', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "#grafico11 = raio_nut.plot(ax=g11, column='800m', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico12 = raio_nut.plot(ax=g12, column='400m_mean', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico13 = raio_nut.plot(ax=g13, column='800m_mean', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "\n",
    "grafico12.set_axis_off()\n",
    "grafico13.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1></h1>\n",
    "<h1>OBJECTIVO 3</h1>\n",
    "<h2>Determinar se a localização dos EFF apresenta depêndencia espacial da localização das schools (ou seja, se os EFFs exibem um padrão de clustering em redor das schools)</h2>\n",
    "\n",
    "- random mcd, bk e tel dentro dos buffers das villages?\n",
    "- ver se ha aleatoriedade ou se há tendendecia de clustering em volta das schools estatisticamente significativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kcross inohomgenous nao executval no python? Tive que exportar para R\n",
    "extraí as \"coordenadas\" da geometria para celulas à parte\n",
    "exportei para shapefile\n",
    "converti em ppp no R (ver https://github.com/jlevente/publications/blob/master/cross-k/calc_crossk.R)\n",
    "\n",
    "fiz a Kcross inhomegenous com envelope:\n",
    "    raio 1500m\n",
    "    lambdaX = villages_ppm (para ter em consideração a maior probabilidade de calhar junto a vilas)\n",
    "    nrank=1 (para definir como min e max do envelope o n-esimo valor mínimo e o nésimo valor maximo\n",
    "    global = TRUE (para homegenizar as curvas e dar um uma probabilidade?)\n",
    "    correction='translation' (? resulta!)\n",
    "\n",
    "<s>Fiz exactamente o mesmo, mas com Lcross inhomegenous, pois esta permite ter um gráfico mais facilmente interpretavel (pois tem menor variação com o r?)\n",
    "Acrescentei na expressao do gráfico \".-r ~ r\", para que a recta da H0 fosse horizontal (e não diagonal)</s>\n",
    "\n",
    "Queria acrescentar as urban à heterogeneidade, mas sendo polígonos torna-se complicado.\n",
    "Nao consigo misturar polygons com pontos, pois ha infinitos pontos dentro de um polygon e vou distorcer a intensidade\n",
    "\n",
    "Como tal, vou criar 2 analises de K functions: \n",
    "    uma fora das zonas urban, window = portugal - urban. tenho de retirar todos os pontos dentro das areas urban e so considerar os outros (atencao à aresta!!)\n",
    "    a outra dentro das areas urban, em que window = urban\n",
    "\n",
    "\n",
    "ver se faz diferença usar na intesnidade (lambdaX) o ppm ou a density\n",
    "\n",
    "falta saber como fazer cloropeth disto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocar na mesma dataframe as schools e os restaurantes para poder passar a ppp. \n",
    "# Note-se que é necessário fazer a distinção entre os dois tipos de ponto de cada dataframe resultante, pelo que\n",
    "# é necessário acrescentar o tipo para poder fazer a distincao dos pontos schools vs restaurante no R na funcao ppp\n",
    "\n",
    "temp_schools = schools.drop(columns=['Lat', 'Lon'])\n",
    "temp_schools.insert(loc=0, column='Tipo', value='escola')\n",
    "\n",
    "# bk, mcd, tel\n",
    "uniao_schools_bk = pandas.concat([bk.drop(columns=['Lat', 'Lon']), temp_schools], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)\n",
    "uniao_schools_mcd = pandas.concat([mcd.drop(columns=['Lat', 'Lon']), temp_schools], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)\n",
    "uniao_schools_tel = pandas.concat([tel.drop(columns=['Lat', 'Lon']), temp_schools], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)\n",
    "\n",
    "# para os restaurantes no geral\n",
    "# Note-se que aqui é preciso acrescentar o tipo da variável restaurante, para distinguir das schools, e aqui\n",
    "# já não importa a distinção entre diferentes tipos de restaurante\n",
    "\n",
    "temp_rest = rest.drop(columns=['Tipo','Lat', 'Lon'])\n",
    "temp_rest.insert(loc=0, column ='Tipo', value='restaurante')\n",
    "uniao_schools_rest = pandas.concat([temp_rest, temp_schools], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniao_schools_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar que tantos os restaurantes, como as schools como as villages ou estão dentro ou fora das areas urban, \n",
    "#de forma a não perder os que poderiam estar nas bordas\n",
    "\n",
    "for a in (villages, uniao_schools_bk, uniao_schools_mcd, uniao_schools_tel, uniao_schools_rest):\n",
    "    print(len(a[a.within(urban_polygon)]) + len(a[a.disjoint(urban_polygon)]) == len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separar dentro das areas urban vs fora\n",
    "uniao_schools_rest_urban = uniao_schools_rest[uniao_schools_rest.within(urban_polygon)]\n",
    "uniao_schools_rest_rural = uniao_schools_rest[uniao_schools_rest.disjoint(urban_polygon)]\n",
    "\n",
    "villages_urban = vilas[vilas.within(urban_polygon)]\n",
    "villages_rural = vilas[vilas.disjoint(urban_polygon)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extração das coordenadas x e y da geometria dos pontos (note-se que estão em CRS diferente das lat e lon originais!)\n",
    "\n",
    "def extrair_xy(lista):\n",
    "    x = [x for x,y in zip(lista['geometry'].x, lista['geometry'].y)]\n",
    "    y = [y for x,y in zip(lista['geometry'].x, lista['geometry'].y)]\n",
    "    lista.insert(loc=len(lista.columns), column='x', value=x)\n",
    "    lista.insert(loc=len(lista.columns), column='y', value=y)\n",
    "    \n",
    "extrair_xy(uniao_schools_bk)\n",
    "extrair_xy(uniao_schools_mcd)\n",
    "extrair_xy(uniao_schools_tel)\n",
    "\n",
    "extrair_xy(villages_urban)\n",
    "extrair_xy(villages_rural)\n",
    "extrair_xy(uniao_schools_rest_urban)\n",
    "extrair_xy(uniao_schools_rest_rural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt_sem_urban\n",
    "rural = portugal[:][['NUTS_LABEL','geometry']]\n",
    "rural['geometry'] = portugal.difference(urban_polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar para shapefile a ser lida n R\n",
    "portugal[['NUTS_LABEL', 'geometry']].to_file('shapefiles/portugal.shp', driver='ESRI Shapefile')\n",
    "rural.to_file('shapefiles/rural.shp', driver='ESRI Shapefile')\n",
    "urban.to_file('shapefiles/urban.shp', driver='ESRI Shapefile')\n",
    "\n",
    "villages_urban.to_file('shapefiles/vilas_urban.shp', driver='ESRI Shapefile')\n",
    "villages_rural.to_file('shapefiles/vilas_rural.shp', driver='ESRI Shapefile')\n",
    "\n",
    "uniao_schools_bk.to_file('shapefiles/bk.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_mcd.to_file('shapefiles/mcd.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_tel.to_file('shapefiles/tel.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_rest.to_file('shapefiles/rest.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_rest_rural.to_file('shapefiles/rest_rural.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_rest_urban.to_file('shapefiles/rest_urban.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
