{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy\n",
    "import pandas\n",
    "import geopandas as gp\n",
    "import csv\n",
    "import shapely.geometry\n",
    "import mapclassify\n",
    "import ipywidgets\n",
    "import ipympl\n",
    "import copy\n",
    "\n",
    "pandas.options.display.max_rows = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the geodataframe from the shapefile and converting to the standard Coordinate \n",
    "# Reference System (CRS) of Portugal \n",
    "\n",
    "def read_shp(path):\n",
    "    gdf = gp.read_file(path, index = False)\n",
    "    gdf = gdf.to_crs(epsg = 3763)\n",
    "    return (gdf)\n",
    "\n",
    "portugal_gdf = read_shp('portugal_map_shapefile/DATA/Countries/PT/NUTS_3.shp')\n",
    "urban_gdf = read_shp('portugal_map_shapefile/DATA/Countries/PT/BuiltupA.shp')\n",
    "villages_gdf = read_shp('portugal_map_shapefile/DATA/Countries/PT/BuiltupP.shp')\n",
    "\n",
    "# Excluding Azores and Madeira, since this study focuses in mainland Portugal; note that\n",
    "# 'intersects' is a better choice than 'within' in the case of 'urban', because part of its \n",
    "# polygons overflow the 'portugal' ones\n",
    "azores = portugal_gdf[(portugal_gdf['NUTS_LABEL'] == 'Região Autónoma dos Açores')].index\n",
    "madeira = portugal_gdf[(portugal_gdf['NUTS_LABEL'] == 'Região Autónoma da Madeira')].index\n",
    "portugal = portugal_gdf.drop(azores.union(madeira))\n",
    "portugal_polygon = portugal.unary_union\n",
    "urban = urban_gdf[urban_gdf['geometry'].intersects(portugal_polygon) == True]\n",
    "villages = villages_gdf[villages_gdf['geometry'].within(portugal_polygon) == True]\n",
    "\n",
    "# Keeping only the relevant information\n",
    "urban = urban[['geometry']]\n",
    "villages = villages[['NAMA1', 'geometry']].rename({'NAMA1':'Nome'}, axis = 1)\n",
    "\n",
    "# Unifying all polygons of urban; this will be useful to check which POI are within 'urban'\n",
    "urban_polygon = urban.unary_union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting raw data from csv files, converting the coordinates to geometric points, building\n",
    "# geodataframes and converting to the standard CRS of Portugal; note that the CRS of the raw \n",
    "# data differs from the standard one, and this must be taken into account when importing\n",
    "\n",
    "def csv_to_gdf(path):\n",
    "    raw = pandas.read_csv(path, sep = ';', index_col = False)\n",
    "    geo = [Point(xy) for xy in zip(raw['Lon'], raw['Lat'])]\n",
    "    gdf = gp.GeoDataFrame(raw, geometry = geo, crs='epsg:4258')\n",
    "    crs = gdf.to_crs(epsg=3763)\n",
    "    return (crs)\n",
    "    \n",
    "bk_crs = csv_to_gdf('points_of_interest/burger_king.csv')\n",
    "mcd_crs = csv_to_gdf('points_of_interest/mcdonalds.csv')\n",
    "tel_crs = csv_to_gdf('points_of_interest/telepizza.csv')\n",
    "schools_crs = csv_to_gdf('points_of_interest/schools.csv')\n",
    "\n",
    "\n",
    "# Test for points outside Portugal (not needed anymore)\n",
    "#bk_crs[bk_crs['geometry'].within(portugal_polygon) == False]\n",
    "#mcd_crs[mcd_crs['geometry'].within(portugal_polygon) == False]\n",
    "#schools_crs[schools_crs['geometry'].within(portugal_polygon) == False]\n",
    "#tel_crs[tel_crs['geometry'].within(portugal_polygon) == False]\n",
    "\n",
    "# This could be used to check for duplicated school coordinates; in this case, it's not relevant,\n",
    "# since we know our database does contain cases of different schools with different levels of\n",
    "# education that have different names, and yet share the same building/area.\n",
    "#schools[schools['geometry'].duplicated(keep=False)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the corresponding NUT to the schools and restaurants GeoDataFrames. Note that the \n",
    "# following operation can only stores one geometry, and since we need to store the geometry\n",
    "# of the points (and not of the NUTs polygons), the reference has to be 'right'\n",
    "\n",
    "def adding_nut(original_variable):\n",
    "    joined = gp.sjoin(portugal, original_variable, predicate='contains', how='right')\n",
    "    if original_variable is schools_crs:\n",
    "        relevant_info = joined[['Nome', 'Lat', 'Lon','NUTS_LABEL', 'geometry']]\n",
    "    else:\n",
    "        relevant_info = joined[['Tipo','Nome', 'Lat', 'Lon','NUTS_LABEL', 'geometry']]\n",
    "    reordered = relevant_info.sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "    return (reordered)\n",
    "\n",
    "bk = adding_nut(bk_crs)\n",
    "mcd = adding_nut(mcd_crs)\n",
    "tel = adding_nut(tel_crs)\n",
    "schools = adding_nut(schools_crs)\n",
    "\n",
    "# Grouping the 3 restaurants brands in a single variable\n",
    "rest = pandas.concat([bk, mcd, tel], ignore_index=True)\n",
    "rest = rest.sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "\n",
    "# Aggregating schools and restaurants according to NUT, so to make choropleth maps. Note that\n",
    "# here the reference has to be 'left', since we need the geometry of the NUTs polygons\n",
    "def join_by_nut(original_variable):\n",
    "    joined = gp.sjoin(portugal, original_variable, predicate='contains', how='left')\n",
    "    relevant_info = joined[['Nome', 'NUTS_LABEL', 'geometry']]\n",
    "    per_nut = relevant_info.dissolve(by='NUTS_LABEL', aggfunc='count')\n",
    "    reordered = per_nut.reset_index().rename({'Nome': 'count'}, axis=1)\n",
    "    return (reordered)\n",
    "\n",
    "schools_nut = join_by_nut(schools_crs)\n",
    "bk_nut = join_by_nut(bk_crs)\n",
    "mcd_nut = join_by_nut(mcd_crs)\n",
    "tel_nut = join_by_nut(tel_crs)\n",
    "rest_nut = join_by_nut(rest.drop(columns='NUTS_LABEL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the schools and restaurants in mainland Portugal\n",
    "\n",
    "%matplotlib widget\n",
    "def interactive_plot():\n",
    "    fig, ax = pyplot.subplots(figsize=(8,10))\n",
    "    fig.set_facecolor((0,0,0))\n",
    "    ax.set_axis_off()\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.95, right=0.85)\n",
    "    fig.suptitle('Nationwide Distribution of Schools \\nand the Top 3 Fast-Food Brands',\n",
    "                 va='top', fontsize=15, fontweight='bold', color='white')\n",
    "\n",
    "    portugal.plot(ax=ax, edgecolor='white', alpha= 0.7, facecolor='black')\n",
    "    villages.plot(ax=ax, edgecolor='white', alpha=0.3, facecolor='none', label='Villages')\n",
    "    schools.plot(ax=ax, color='green', alpha=0.9, markersize=5, label='Schools')\n",
    "    bk.plot(ax=ax, color='red', alpha= 0.7, markersize=5, label ='Burger King')\n",
    "    mcd.plot(ax=ax, color='red', alpha=0.7, markersize=5, label = 'McDonalds')\n",
    "    tel.plot(ax=ax, color='red', alpha= 0.7, markersize=5, label = 'Telepizza')\n",
    "    urban.plot(ax=ax, color='white', alpha=0.4)\n",
    "    \n",
    "    # Not all handles can be turned into legend entries automatically, so it is often necessary\n",
    "    # to create an artist which can; in this case, 'urban' has no legend in the map\n",
    "    # from: https://matplotlib.org/tutorials/intermediate/legend_guide.html\n",
    "\n",
    "    ax.legend(loc='upper left', \n",
    "              bbox_to_anchor=(1, 0.5),\n",
    "              fontsize=13,\n",
    "              labelcolor ='white',\n",
    "              facecolor='black',\n",
    "              borderaxespad=0)\n",
    "    \n",
    "    scalebar = ScaleBar(dx=1, \n",
    "                        length_fraction=0.4, \n",
    "                        location='lower right', \n",
    "                        color='white',\n",
    "                        box_color='black',\n",
    "                        sep=7,\n",
    "                        pad=0,\n",
    "                        border_pad=0)\n",
    "    pyplot.gca().add_artist(scalebar)\n",
    "    leg = interactive_legend()\n",
    "    return fig, ax, leg\n",
    "\n",
    "# The following functions were taken from an answer on SOF (kudos to ImportanceofBeingErnest and\n",
    "# Joe Kington) \n",
    "# from: https://stackoverflow.com/questions/31410043/hiding-lines-after-showing-a-pyplot-figure\n",
    "\n",
    "def interactive_legend(ax=None):\n",
    "    if ax is None:\n",
    "        ax = pyplot.gca()\n",
    "    if ax.legend_ is None:\n",
    "        ax.legend()\n",
    "\n",
    "    return InteractiveLegend(ax.get_legend())\n",
    "\n",
    "class InteractiveLegend(object):\n",
    "    def __init__(self, legend):\n",
    "        self.legend = legend\n",
    "        self.fig = legend.axes.figure\n",
    "\n",
    "        self.lookup_artist, self.lookup_handle = self._build_lookups(legend)\n",
    "        self._setup_connections()\n",
    "\n",
    "        self.update()\n",
    "\n",
    "    def _setup_connections(self):\n",
    "        for artist in self.legend.texts + self.legend.legendHandles:\n",
    "            artist.set_picker(10) # 10 points tolerance\n",
    "\n",
    "        self.fig.canvas.mpl_connect('pick_event', self.on_pick)\n",
    "        self.fig.canvas.mpl_connect('button_press_event', self.on_click)\n",
    "\n",
    "    def _build_lookups(self, legend):\n",
    "        labels = [t.get_text() for t in legend.texts]\n",
    "        handles = legend.legendHandles\n",
    "        label2handle = dict(zip(labels, handles))\n",
    "        handle2text = dict(zip(handles, legend.texts))\n",
    "\n",
    "        lookup_artist = {}\n",
    "        lookup_handle = {}\n",
    "        for artist in legend.axes.get_children():\n",
    "            if artist.get_label() in labels:\n",
    "                handle = label2handle[artist.get_label()]\n",
    "                lookup_handle[artist] = handle\n",
    "                lookup_artist[handle] = artist\n",
    "                lookup_artist[handle2text[handle]] = artist\n",
    "\n",
    "        lookup_handle.update(zip(handles, handles))\n",
    "        lookup_handle.update(zip(legend.texts, handles))\n",
    "\n",
    "        return lookup_artist, lookup_handle\n",
    "\n",
    "    def on_pick(self, event):\n",
    "        handle = event.artist\n",
    "        if handle in self.lookup_artist:\n",
    "\n",
    "            artist = self.lookup_artist[handle]\n",
    "            artist.set_visible(not artist.get_visible())\n",
    "            self.update()\n",
    "\n",
    "    def on_click(self, event):\n",
    "        if event.button == 3:\n",
    "            visible = False\n",
    "        elif event.button == 2:\n",
    "            visible = True\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        for artist in self.lookup_artist.values():\n",
    "            artist.set_visible(visible)\n",
    "        self.update()\n",
    "\n",
    "    def update(self):\n",
    "        for artist in self.lookup_artist.values():\n",
    "            handle = self.lookup_handle[artist]\n",
    "            if artist.get_visible():\n",
    "                handle.set_visible(True)\n",
    "            else:\n",
    "                handle.set_visible(False)\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def show(self):\n",
    "        pyplot.show()\n",
    "\n",
    "schools_restaurants_plot = interactive_plot()\n",
    "schools_restaurants_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the total schools and restaurants in Portugal, per NUTS3\n",
    "%matplotlib inline\n",
    "\n",
    "subplot_vars = [schools_nut, rest_nut, bk_nut, mcd_nut, tel_nut]\n",
    "subplot_titles = [\"Schools\", \"Top 3 Fast-Food Brands\", \"Burguer King\", \"McDonalds\", \"Telepizza\"]\n",
    "fig, axes = pyplot.subplots(nrows=1, ncols=5, figsize=(20,8))\n",
    "fig.set_facecolor((0,0,0))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.85)\n",
    "fig.suptitle('Schools and the Top 3 Fast-Food Brands in Portugal: Count per NUTS3',\n",
    "             va='top', fontsize=24, fontweight='bold', color='white')\n",
    "\n",
    "def plot_nut():\n",
    "    for name, i, j in zip(subplot_vars, axes, subplot_titles):\n",
    "        name.plot(ax=i, \n",
    "                  column='count',\n",
    "                  figsize=(4,8),\n",
    "                  scheme='FisherJenks',\n",
    "                  cmap='Blues',\n",
    "                  edgecolor=(1,1,1,0.5))\n",
    "        i.set_axis_off()\n",
    "        i.set_title(j, fontsize=20, fontweight='bold', color='white')\n",
    "        \n",
    "plot_nut()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>GOAL #1</h1>\n",
    "<h2>Calculate the distance between each school and its closest fast-food restaurant, and identify the regions where that distance is smaller.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each school, find the closest fast-food restaurant and get the distance between them\n",
    "# from: gis.stackexchange.com/questions/222315/geopandas-find-nearest-point-in-other-dataframe\n",
    "\n",
    "def ckdnearest(gdA, gdB):\n",
    "    nA = numpy.array(list(gdA.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    nB = numpy.array(list(gdB.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    btree = cKDTree(nB)\n",
    "    dist, idx = btree.query(nA, k=1)\n",
    "    gdf = pandas.concat([gdA.reset_index(drop=True),\n",
    "                         gdB.loc[idx, gdB.columns != 'geometry'].reset_index(drop=True),\n",
    "                         pandas.Series(dist, name='dist')],\n",
    "                        axis=1)\n",
    "    gdf['dist'] = gdf['dist'] / 1000  #conversao de m para km\n",
    "    return gdf\n",
    "\n",
    "schools_temp = schools.drop(columns=['Lat', 'Lon']).rename({'Nome':'ESCOLA'}, axis =1)\n",
    "rest_temp = rest.drop(columns=['Lat', 'Lon', 'NUTS_LABEL'])\n",
    "prox = ckdnearest(schools_temp, rest_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating the distance between the closest school-restaurant per NUTS3, in order to make a \n",
    "# choropleth map. Notice that we're doing so using 4 different measures. In the end, the median\n",
    "# is the one we're looking for, since it's less sensitive to outliers\n",
    "prox = prox.drop(columns=['NUTS_LABEL'])\n",
    "\n",
    "def aggregate_prox(measure):\n",
    "    joined = gp.sjoin(portugal, prox, predicate='contains', how='left')\n",
    "    if measure in ('mean', 'median'):\n",
    "        trimmed = joined[['NUTS_LABEL','geometry','ESCOLA','Nome','dist']]\n",
    "    else:\n",
    "        trimmed = joined[['NUTS_LABEL','geometry','dist']]\n",
    "    dissolved = trimmed.dissolve(by='NUTS_LABEL', aggfunc=measure).reset_index()\n",
    "    renamed = dissolved.rename({'dist': measure}, axis=1)\n",
    "    return (renamed)\n",
    "\n",
    "prox_mean = aggregate_prox('mean') \n",
    "prox_median = aggregate_prox('median')\n",
    "prox_min = aggregate_prox('min')\n",
    "prox_max = aggregate_prox('max')\n",
    "\n",
    "prox_nut = prox_mean.merge(prox_min.drop(columns='geometry'), on='NUTS_LABEL')\n",
    "prox_nut = prox_nut.merge(prox_median.drop(columns='geometry'), on='NUTS_LABEL')\n",
    "prox_nut = prox_nut.merge(prox_max.drop(columns='geometry'), on='NUTS_LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_nut\n",
    "\n",
    "# Not needed, it was just to test an interactive table\n",
    "#@ipywidgets.interact\n",
    "#def show_articles_more_than(column=['median', 'min'], x=(0, 35, 1)):\n",
    "#    return prox_nut.loc[prox_nut[column] < x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Median Distance (in km) from Schools to the Closest Fast-Food Restaurant\n",
    "%matplotlib widget\n",
    "fig, ax = pyplot.subplots(figsize=(8,10))\n",
    "fig.set_facecolor((0,0,0))\n",
    "ax.set_axis_off()\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95, right=0.85)\n",
    "fig.suptitle('Median Distance (in km) from Schools \\nto the Closest Fast-Food Restaurant',\n",
    "             va='top', fontsize=15, fontweight='bold', color='white')\n",
    "prox_nut.plot(ax=ax, \n",
    "              column='median',\n",
    "              legend=True,\n",
    "              legend_kwds={'bbox_to_anchor':(1.3, 0.5),\n",
    "                           'fontsize':13,\n",
    "                           'labelcolor':'white',\n",
    "                           'facecolor':'black',\n",
    "                           'borderaxespad':0},\n",
    "              scheme='FisherJenks',\n",
    "              cmap='Reds_r',\n",
    "              edgecolor=(1,1,1,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>GOAL #2</h1>\n",
    "<h2>Calculate how many restaurants are within 5 and 10min walking distance from each school, and identify the regions where this number is higher.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many restaurants are within 5 and 10min walking distance from each school. Note\n",
    "# that 5min and 10min walking distance correspond to approximately 400m and 800m.\n",
    "\n",
    "i = 0\n",
    "radius = copy.deepcopy(schools) # Deep copy does an actual copy (instead of a new linked object)\n",
    "radius['400m'] = ''\n",
    "radius['800m'] = ''\n",
    "\n",
    "for i in range(len(schools)):\n",
    "    radius.loc[i,'400m'] = len(rest[rest['geometry'].within(schools['geometry'][i].buffer(400))])\n",
    "    radius.loc[i,'800m'] = len(rest[rest['geometry'].within(schools['geometry'][i].buffer(800))])\n",
    "\n",
    "radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating the number of restaurantes within short distance per NUTS3, in order to make a \n",
    "# choropleth map. Notice that we're doing so using both sum and mean.\n",
    "radius = radius.drop(columns=['NUTS_LABEL'])\n",
    "\n",
    "def aggregate_radius(measure):\n",
    "    joined = gp.sjoin(portugal, radius, predicate='contains', how='left')\n",
    "    trimmed = joined[['NUTS_LABEL','geometry','Nome','400m','800m']]\n",
    "    dissolved = trimmed.dissolve(by='NUTS_LABEL', aggfunc=measure).reset_index()\n",
    "    if measure == 'sum':\n",
    "        dissolved = dissolved.rename({'400m': '400m Sum', '800m': '800m Sum'}, axis=1)\n",
    "    return (dissolved)\n",
    "        \n",
    "\n",
    "radius_sum = aggregate_radius('sum')\n",
    "radius_mean = aggregate_radius('mean')\n",
    "radius_nut = radius_sum.merge(radius_mean.drop(columns=['geometry']), on='NUTS_LABEL')\n",
    "radius_nut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Mean Number of Restaurants Within Walking Distance of Schools\n",
    "%matplotlib inline\n",
    "subplot_titles = [\"400m\", \"800m\"]\n",
    "fig, axes = pyplot.subplots(nrows=1, ncols=2, figsize=(13,10))\n",
    "fig.set_facecolor((0,0,0))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.85)\n",
    "fig.suptitle('Mean Number of Restaurants \\nWithin Walking Distance of Schools',\n",
    "             va='top', x=0.56, fontsize=24, fontweight='bold', color='white')\n",
    "\n",
    "def plot_radius(name):\n",
    "    for i, j in zip(axes, subplot_titles):\n",
    "        name.plot(ax=i, \n",
    "                  column=j,\n",
    "                  scheme='FisherJenks',\n",
    "                  cmap='Reds',\n",
    "                  edgecolor=(1,1,1,0.5),\n",
    "                  legend=True,\n",
    "                  legend_kwds={'loc': 'right',\n",
    "                               'fontsize':13,\n",
    "                               'labelcolor':'white',\n",
    "                               'facecolor':'black',\n",
    "                               'borderaxespad':-10})\n",
    "        i.set_axis_off()\n",
    "        i.set_title(j, fontsize=20, fontweight='bold', color='white')\n",
    "        \n",
    "plot_radius(radius_nut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1></h1>\n",
    "<h1>OBJECTIVO 3</h1>\n",
    "<h2>Determinar se a localização dos EFF apresenta depêndencia espacial da localização das schools (ou seja, se os EFFs exibem um padrão de clustering em redor das schools)</h2>\n",
    "\n",
    "- random mcd, bk e tel dentro dos buffers das villages?\n",
    "- ver se ha aleatoriedade ou se há tendendecia de clustering em volta das schools estatisticamente significativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kcross inohomgenous nao executval no python? Tive que exportar para R\n",
    "extraí as \"coordenadas\" da geometria para celulas à parte\n",
    "exportei para shapefile\n",
    "converti em ppp no R (ver https://github.com/jlevente/publications/blob/master/cross-k/calc_crossk.R)\n",
    "\n",
    "fiz a Kcross inhomegenous com envelope:\n",
    "    raio 1500m\n",
    "    lambdaX = villages_ppm (para ter em consideração a maior probabilidade de calhar junto a vilas)\n",
    "    nrank=1 (para definir como min e max do envelope o n-esimo valor mínimo e o nésimo valor maximo\n",
    "    global = TRUE (para homegenizar as curvas e dar um uma probabilidade?)\n",
    "    correction='translation' (? resulta!)\n",
    "\n",
    "<s>Fiz exactamente o mesmo, mas com Lcross inhomegenous, pois esta permite ter um gráfico mais facilmente interpretavel (pois tem menor variação com o r?)\n",
    "Acrescentei na expressao do gráfico \".-r ~ r\", para que a recta da H0 fosse horizontal (e não diagonal)</s>\n",
    "\n",
    "Queria acrescentar as urban à heterogeneidade, mas sendo polígonos torna-se complicado.\n",
    "Nao consigo misturar polygons com pontos, pois ha infinitos pontos dentro de um polygon e vou distorcer a intensidade\n",
    "\n",
    "Como tal, vou criar 2 analises de K functions: \n",
    "    uma fora das zonas urban, window = portugal - urban. tenho de retirar todos os pontos dentro das areas urban e so considerar os outros (atencao à aresta!!)\n",
    "    a outra dentro das areas urban, em que window = urban\n",
    "\n",
    "\n",
    "ver se faz diferença usar na intesnidade (lambdaX) o ppm ou a density\n",
    "\n",
    "falta saber como fazer cloropeth disto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocar na mesma dataframe as schools e os restaurantes para poder passar a ppp. \n",
    "# Note-se que é necessário fazer a distinção entre os dois tipos de ponto de cada dataframe resultante, pelo que\n",
    "# é necessário acrescentar o tipo para poder fazer a distincao dos pontos schools vs restaurante no R na funcao ppp\n",
    "\n",
    "temp_schools = schools.drop(columns=['Lat', 'Lon'])\n",
    "temp_schools.insert(loc=0, column='Tipo', value='escola')\n",
    "\n",
    "# bk, mcd, tel\n",
    "uniao_schools_bk = pandas.concat([bk.drop(columns=['Lat', 'Lon']), temp_schools], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)\n",
    "uniao_schools_mcd = pandas.concat([mcd.drop(columns=['Lat', 'Lon']), temp_schools], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)\n",
    "uniao_schools_tel = pandas.concat([tel.drop(columns=['Lat', 'Lon']), temp_schools], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)\n",
    "\n",
    "# para os restaurantes no geral\n",
    "# Note-se que aqui é preciso acrescentar o tipo da variável restaurante, para distinguir das schools, e aqui\n",
    "# já não importa a distinção entre diferentes tipos de restaurante\n",
    "\n",
    "temp_rest = rest.drop(columns=['Tipo','Lat', 'Lon'])\n",
    "temp_rest.insert(loc=0, column ='Tipo', value='restaurante')\n",
    "uniao_schools_rest = pandas.concat([temp_rest, temp_schools], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniao_schools_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar que tantos os restaurantes, como as schools como as villages ou estão dentro ou fora das areas urban, \n",
    "#de forma a não perder os que poderiam estar nas bordas\n",
    "\n",
    "for a in (villages, uniao_schools_bk, uniao_schools_mcd, uniao_schools_tel, uniao_schools_rest):\n",
    "    print(len(a[a.within(urban_polygon)]) + len(a[a.disjoint(urban_polygon)]) == len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separar dentro das areas urban vs fora\n",
    "uniao_schools_rest_urban = uniao_schools_rest[uniao_schools_rest.within(urban_polygon)]\n",
    "uniao_schools_rest_rural = uniao_schools_rest[uniao_schools_rest.disjoint(urban_polygon)]\n",
    "\n",
    "villages_urban = vilas[vilas.within(urban_polygon)]\n",
    "villages_rural = vilas[vilas.disjoint(urban_polygon)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extração das coordenadas x e y da geometria dos pontos (note-se que estão em CRS diferente das lat e lon originais!)\n",
    "\n",
    "def extrair_xy(lista):\n",
    "    x = [x for x,y in zip(lista['geometry'].x, lista['geometry'].y)]\n",
    "    y = [y for x,y in zip(lista['geometry'].x, lista['geometry'].y)]\n",
    "    lista.insert(loc=len(lista.columns), column='x', value=x)\n",
    "    lista.insert(loc=len(lista.columns), column='y', value=y)\n",
    "    \n",
    "extrair_xy(uniao_schools_bk)\n",
    "extrair_xy(uniao_schools_mcd)\n",
    "extrair_xy(uniao_schools_tel)\n",
    "\n",
    "extrair_xy(villages_urban)\n",
    "extrair_xy(villages_rural)\n",
    "extrair_xy(uniao_schools_rest_urban)\n",
    "extrair_xy(uniao_schools_rest_rural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt_sem_urban\n",
    "rural = portugal[:][['NUTS_LABEL','geometry']]\n",
    "rural['geometry'] = portugal.difference(urban_polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar para shapefile a ser lida n R\n",
    "portugal[['NUTS_LABEL', 'geometry']].to_file('shapefiles/portugal.shp', driver='ESRI Shapefile')\n",
    "rural.to_file('shapefiles/rural.shp', driver='ESRI Shapefile')\n",
    "urban.to_file('shapefiles/urban.shp', driver='ESRI Shapefile')\n",
    "\n",
    "villages_urban.to_file('shapefiles/vilas_urban.shp', driver='ESRI Shapefile')\n",
    "villages_rural.to_file('shapefiles/vilas_rural.shp', driver='ESRI Shapefile')\n",
    "\n",
    "uniao_schools_bk.to_file('shapefiles/bk.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_mcd.to_file('shapefiles/mcd.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_tel.to_file('shapefiles/tel.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_rest.to_file('shapefiles/rest.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_rest_rural.to_file('shapefiles/rest_rural.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_rest_urban.to_file('shapefiles/rest_urban.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
