{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib  inline\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy\n",
    "import pandas\n",
    "import geopandas\n",
    "import csv\n",
    "import shapely.geometry\n",
    "import mapclassify\n",
    "import ipywidgets\n",
    "\n",
    "pandas.options.display.max_rows = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the polygon of mainland Portugal from the map shapefile, dropping the islands.\n",
    "whole_portugal = geopandas.read_file('portugal_map_shapefile/DATA/Countries/PT/NUTS_3.shp', index=False)\n",
    "islands = portugal_geo[(portugal_geo['NUTS_LABEL'] == 'Região Autónoma dos Açores') | (portugal_geo['NUTS_LABEL'] == 'Região Autónoma da Madeira')].index\n",
    "mainland_portugal = portugal_geo.drop(index=islands)\n",
    "portugal = mainland_portugal.to_crs(epsg=3763)\n",
    "\n",
    "# Testing whether all the schools and restaurants coordinates are within mainland Portugal\n",
    "portugal_polygon = portugal.unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractig the polygons of the denser metropolitan areas\n",
    "urbanas_geo = geopandas.read_file('portugal_map_shapefile/DATA/Countries/PT/BuiltupA.shp', index=False)\n",
    "urbanas = urbanas_geo.to_crs(epsg=3763)\n",
    "urbanas = urbanas[urbanas['geometry'].intersects(portugal_poligono) == True] #excluir as regioes autonomas\n",
    "urbanas = urbanas[['geometry']]\n",
    "urbanas_poligono = urbanas.unary_union\n",
    "# Nota: como parte dos poligonos das urbanas ultrapassam ligeiramente o bordo do poligono portugal,\n",
    "#tenho que usar .intersects e não .within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vilas_geo = geopandas.read_file('portugal_map_shapefile/DATA/Countries/PT/BuiltupP.shp', index=False)\n",
    "vilas = vilas_geo.to_crs(epsg=3763)\n",
    "vilas = vilas[vilas['geometry'].within(portugal_poligono) == True] #excluir as regioes autonomas\n",
    "vilas = vilas[['NAMA1','geometry']].rename({'NAMA1':'Nome'}, axis =1) #manter apenas info relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escolas_original = pandas.read_csv('points_of_interest/schools.csv', sep = ';', index_col=False)\n",
    "geometry_escolas = [Point(xy) for xy in zip(escolas_original['Lon'], escolas_original['Lat'])]\n",
    "escolas_geo = geopandas.GeoDataFrame(escolas_original, geometry=geometry_escolas, crs='EPSG:4258') #confirmar epsg dce origem\n",
    "escolas_crs = escolas_geo.to_crs(epsg=3763)\n",
    "escolas_crs[escolas_crs['geometry'].within(portugal_poligono) == False] #testar coordenadas erradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd_original = pandas.read_csv('points_of_interest/mcdonalds.csv', sep = ';', index_col=False)\n",
    "geometry_mcd = [Point(xy) for xy in zip(mcd_original['Lon'], mcd_original['Lat'])]\n",
    "mcd_geo = geopandas.GeoDataFrame(mcd_original, geometry=geometry_mcd, crs='EPSG:4258') #nao deveria ser 3857? retirado do gmaps, right?\n",
    "mcd_crs = mcd_geo.to_crs(epsg=3763)\n",
    "mcd_crs[mcd_crs['geometry'].within(portugal_poligono) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tel_original = pandas.read_csv('points_of_interest/telepizza.csv', sep = ';', index_col=False)\n",
    "geometry_tel = [Point(xy) for xy in zip(tel_original['Lon'], tel_original['Lat'])]\n",
    "tel_geo = geopandas.GeoDataFrame(tel_original, geometry=geometry_tel, crs='EPSG:4258') #nao deveria ser 3857? retirado do gmaps, right?\n",
    "tel_crs = tel_geo.to_crs(epsg=3763)\n",
    "tel_crs[tel_crs['geometry'].within(portugal_poligono) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_original = pandas.read_csv('points_of_interest/burger_king.csv', sep = ';', index_col=False)\n",
    "geometry_bk = [Point(xy) for xy in zip(bk_original['Lon'], bk_original['Lat'])]\n",
    "bk_geo = geopandas.GeoDataFrame(bk_original, geometry=geometry_bk, crs='EPSG:4258') #nao deveria ser 3857? retirado do applemaps, right?\n",
    "bk_crs = bk_geo.to_crs(epsg=3763)\n",
    "bk_crs[bk_crs['geometry'].within(portugal_poligono) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acrescentar NUT correspondente na base de dados das escolas e dos restaurantes\n",
    "escolas = geopandas.sjoin(portugal, escolas_crs, predicate='contains', how='right')[['Nome', 'Lat', 'Lon', 'NUTS_LABEL', 'geometry']].sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "bk = geopandas.sjoin(portugal, bk_crs, predicate='contains', how='right')[['Tipo','Nome', 'Lat', 'Lon','NUTS_LABEL', 'geometry']].sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "mcd = geopandas.sjoin(portugal, mcd_crs, predicate='contains', how='right')[['Tipo','Nome', 'Lat', 'Lon','NUTS_LABEL', 'geometry']].sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "tel = geopandas.sjoin(portugal, tel_crs, predicate='contains', how='right')[['Tipo','Nome', 'Lat', 'Lon','NUTS_LABEL', 'geometry']].sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "\n",
    "#  NOTA: aqui, a referência tem que ser sempre 'right' para ir buscar as coordenadas dos pontos \n",
    "#  (e não as coordenadas dos poligonos dos NUTs), pois esta operação so guarda uma geometria\n",
    "\n",
    "#criar variável com todos os 3 tipos de restaurantes\n",
    "rest = pandas.concat([mcd, bk, tel], ignore_index=True).sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# agregar escolas e restaurantes por NUT para poder fazer choropleth\n",
    "escolas_nut = geopandas.sjoin(portugal, escolas_crs, predicate='contains', how='left')[['Nome', 'NUTS_LABEL', 'geometry']].dissolve(by='NUTS_LABEL', aggfunc='count').reset_index().rename({'Nome': 'count'}, axis=1)\n",
    "bk_nut = geopandas.sjoin(portugal, bk_crs, predicate='contains', how='left')[['Nome','NUTS_LABEL', 'geometry']].dissolve(by='NUTS_LABEL', aggfunc='count').reset_index().rename({'Nome': 'count'}, axis=1)\n",
    "mcd_nut = geopandas.sjoin(portugal, mcd_crs, predicate='contains', how='left')[['Nome', 'NUTS_LABEL', 'geometry']].dissolve(by='NUTS_LABEL', aggfunc='count').reset_index().rename({'Nome': 'count'}, axis=1)\n",
    "tel_nut = geopandas.sjoin(portugal, tel_crs, predicate='contains', how='left')[['Nome','NUTS_LABEL', 'geometry']].dissolve(by='NUTS_LABEL', aggfunc='count').reset_index().rename({'Nome': 'count'}, axis=1)\n",
    "rest_nut = geopandas.sjoin(portugal, rest.drop(columns='NUTS_LABEL'), predicate='contains', how='left')[['Nome','NUTS_LABEL', 'geometry']].dissolve(by='NUTS_LABEL', aggfunc='count').reset_index().rename({'Nome': 'count'}, axis=1)\n",
    "\n",
    "#  NOTA: aqui, a referência já tem que ser sempre 'left' para ir buscar as coordenadas dos polígonos dos NUTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirmar se há coordenadas iguais, o que há, porque escolas de ensinos diferentes e, como tal, com \n",
    "# nomes diferentes podem estar no mesmo edifício\n",
    "\n",
    "#escolas[escolas['geometry'].duplicated(keep=False)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forma alternativa de converter df em gdf: \n",
    "#df['Coordinates']  = list(zip(df.Longitude, df.Latitude))\n",
    "#df['Coordinates'] = df['Coordinates'].apply(Point)\n",
    "#gdf = geopandas.GeoDataFrame(df, geometry='Coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grafico DEPOIS de mudar as coordenadas para UTM com unidades em metros\n",
    "fig, ax = pyplot.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
    "\n",
    "ax.set_axis_off()\n",
    "portugal.plot(ax=ax, edgecolor='k', alpha= 0.7, facecolor='white', figsize=(15,15))\n",
    "escolas.plot(ax=ax, color='blue', alpha=0.5, label='Escolas')\n",
    "bk.plot(ax=ax, color='red', alpha= 0.2, label ='Restaurantes')\n",
    "mcd.plot(ax=ax, color='red', alpha=0.2, markersize=7)\n",
    "tel.plot(ax=ax, color='red', alpha= 0.2, markersize=7)\n",
    "ax.legend(fontsize=16,\n",
    "         loc=(-0.4, 0.5),\n",
    "         frameon=False)\n",
    "\n",
    "scalebar = ScaleBar(dx=1, length_fraction=0.4, location='lower right', color='black',sep=7, pad=0, border_pad=0)\n",
    "pyplot.gca().add_artist(scalebar)\n",
    "\n",
    "\n",
    "\n",
    "#pp.title('urbanas', fontweight='bold')\n",
    "\n",
    "\n",
    "\n",
    "#tirar os eixos mas manter um background cor diferente\n",
    "#ax.set_facecolor((0, 0, 0, 0.05))\n",
    "#ax.set_axis_off()\n",
    "#ax.add_artist(ax.patch)\n",
    "#ax.patch.set_zorder(-1)\n",
    "\n",
    "\n",
    "\n",
    "#grafico1.set(xlim=(-100000, -80000), ylim=(-115000,-95000)) #lisboa \n",
    "\n",
    "\n",
    "#grafico1.set(xlim=(-150000, 170000), ylim=(-310000,285000))\n",
    "#grafico1.set(xlim=(-130000, -55000), ylim=(-150000,-50000)) #lisboa \n",
    "#grafico1.set(xlim=(-60000, 0), ylim=(140000,180000)) #porto\n",
    "\n",
    "#teste pontos\n",
    "#grafico1.set(xlim=(-60000, 0), ylim=(90000,180000))\n",
    "#escolas.loc[[0], 'geometry'].plot(ax=grafico1, color='blue', alpha=1, markersize=15)\n",
    "#rest.loc[[1], 'geometry'].plot(ax=grafico1, color='black', alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
    "\n",
    "ax.set_axis_off()\n",
    "portugal.plot(ax=ax, edgecolor='k', alpha= 0.7, facecolor='white', figsize=(15,15))\n",
    "urbanas.plot(ax=ax, color='red', alpha=0.8)\n",
    "\n",
    "#Not all handles can be turned into legend entries automatically, so it is often necessary to create an artist which can\n",
    "#ver em https://matplotlib.org/tutorials/intermediate/legend_guide.html\n",
    "red_patch = mpatches.Patch(color='red', label='Urbanas')\n",
    "\n",
    "\n",
    "ax.legend(handles=[red_patch],\n",
    "          fontsize=16,\n",
    "         loc=(-0.4, 0.5),\n",
    "         frameon=False)\n",
    "\n",
    "scalebar = ScaleBar(dx=1, length_fraction=0.4, location='lower right', color='black',sep=7, pad=0, border_pad=0)\n",
    "pyplot.gca().add_artist(scalebar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
    "\n",
    "ax.set_axis_off()\n",
    "portugal.plot(ax=ax, edgecolor='k', alpha= 0.7, facecolor='white', figsize=(15,15))\n",
    "vilas.plot(ax=ax, color='crimson', facecolor='none', label='Vilas')\n",
    "ax.legend(fontsize=20,\n",
    "         loc=(-0.4, 0.5),\n",
    "         frameon=False)\n",
    "\n",
    "scalebar = ScaleBar(dx=1, length_fraction=0.4, location='lower right', color='black',sep=7, pad=0, border_pad=0)\n",
    "pyplot.gca().add_artist(scalebar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribuiçao nacional das escolas e de cada restaurante, por NUT\n",
    "fig, (g2, g3, g4, g5, g6) = pyplot.subplots(nrows=1, ncols=5, figsize=(20, 16))\n",
    "pyplot.tight_layout()\n",
    "\n",
    "grafico2 = escolas_nut.plot(ax=g2, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico3 = bk_nut.plot(ax=g3, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico4 = mcd_nut.plot(ax=g4, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico5 = tel_nut.plot(ax=g5, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico6 = rest_nut.plot(ax=g6, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1></h1>\n",
    "<h1>OBJECTIVO 1</h1>\n",
    "<h2>Determinar, para cada escola em Portugal continental, qual a proximidade ao estabelecimento de fast-food (EFF) mais próximo</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mudei os nomes das entradas para Capitalized\n",
    "#acrescentei o tipo de rest nos csv dos mcd e tel\n",
    "#padronizei os labels das colunas\n",
    "#comparei visualmente no mapa para ver se batia certo\n",
    "\n",
    "\n",
    "#retirado de https://gis.stackexchange.com/questions/222315/geopandas-find-nearest-point-in-other-dataframe\n",
    "\n",
    "def ckdnearest(gdA, gdB):\n",
    "    nA = numpy.array(list(gdA.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    nB = numpy.array(list(gdB.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    btree = cKDTree(nB)\n",
    "    dist, idx = btree.query(nA, k=1)\n",
    "    gdf = pandas.concat(\n",
    "        [gdA.reset_index(drop=True), gdB.loc[idx, gdB.columns != 'geometry'].reset_index(drop=True),\n",
    "         pandas.Series(dist, name='dist')], axis=1)\n",
    "    gdf['dist'] = gdf['dist'] / 1000  #conversao de m para km\n",
    "    return gdf\n",
    "\n",
    "prox = ckdnearest(escolas.drop(columns=['Lat', 'Lon']).rename({'Nome':'ESCOLA'}, axis =1), rest.drop(columns=['Lat', 'Lon', 'NUTS_LABEL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar escolas e restaurantes por NUT para poder fazer choropleth\n",
    "# criar as estatisticas por NUTs\n",
    "\n",
    "prox_mean = geopandas.sjoin(portugal, prox.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','ESCOLA','Nome','dist']].dissolve(by='NUTS_LABEL', aggfunc='mean').reset_index().rename({'dist': 'mean'}, axis=1)\n",
    "prox_median = geopandas.sjoin(portugal, prox.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','ESCOLA','Nome','dist']].dissolve(by='NUTS_LABEL', aggfunc='median').reset_index().rename({'dist': 'median'}, axis=1)\n",
    "prox_min = geopandas.sjoin(portugal, prox.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','dist']].dissolve(by='NUTS_LABEL', aggfunc='min').reset_index().rename({'dist': 'min'}, axis=1)\n",
    "prox_max = geopandas.sjoin(portugal, prox.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','dist']].dissolve(by='NUTS_LABEL', aggfunc='max').reset_index().rename({'dist': 'max'}, axis=1)\n",
    "\n",
    "prox_nut = prox_mean.merge(prox_min.drop(columns='geometry'), on='NUTS_LABEL').merge(prox_median.drop(columns='geometry'), on='NUTS_LABEL').merge(prox_max.drop(columns='geometry'), on='NUTS_LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_nut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact\n",
    "def show_articles_more_than(column=['median', 'min'], x=(0, 35, 1)):\n",
    "    return prox_nut.loc[prox_nut[column] < x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, (g7, g8, g9) = pyplot.subplots(nrows=1, ncols=3, figsize=(20, 16))\n",
    "#usamos a mediana pois ha outliers\n",
    "pyplot.tight_layout()\n",
    "\n",
    "grafico7 = prox_nut.plot(column='median', figsize=(20,16), legend=True, scheme='FisherJenks', cmap='Greens_r', edgecolor='k')\n",
    "grafico7.set_axis_off()\n",
    "#grafico8 = prox_nut.plot(ax=g8, column='min', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens_r', edgecolor='k')\n",
    "#grafico9 = prox_nut.plot(ax=g9, column='max', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens_r', edgecolor='k')\n",
    "#fig.canvas.toolbar_visible = False\n",
    "#fig.canvas.header_visible = False\n",
    "#fig.canvas.resizable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.distplot(prox_nut['min'], rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1></h1>\n",
    "<h1>OBJECTIVO 2</h1>\n",
    "<h2>Determinar, para cada escola em Portugal continental, quantos EFF estão a curta distância (raios de 5 e de 10min a pé)</h2>\n",
    "<h1>SEEMS TO BE WORKING UNTIL HERE</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada escola, criar um raio de 400m e de 800m e contar quantos rest estão nesse círculos\n",
    "i = 0\n",
    "raio = escolas[:]  # slice op para copiar o conteúdo e não linkar à variável antiga\n",
    "raio['400m'] = ''  # criar novas duas colunas vazias\n",
    "raio['800m'] = ''\n",
    "\n",
    "for i in range(len(escolas)):\n",
    "    raio.loc[i,'400m'] = len(rest[rest['geometry'].within(escolas['geometry'][i].buffer(400))])\n",
    "    raio.loc[i,'800m'] = len(rest[rest['geometry'].within(escolas['geometry'][i].buffer(800))])\n",
    "\n",
    "raio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar dados raio por NUT para poder fazer choropleth\n",
    "# soma\n",
    "raio_nut = geopandas.sjoin(portugal, raio.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','Nome','400m','800m']].dissolve(by='NUTS_LABEL', aggfunc='sum').reset_index()\n",
    "\n",
    "\n",
    "# média de restaurantes no raio especificado para as escolas de cada NUT\n",
    "raio_mean = geopandas.sjoin(portugal, raio.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','400m','800m']]\n",
    "raio_mean[['400m', '800m']] = raio_mean[['400m', '800m']].apply(pandas.to_numeric) # por algum motivo que desconheço, estas colunas aparecem como objectos e impossibilitam a obtenção da média, pelo que tenho de converter em números\n",
    "raio_mean = raio_mean.dissolve(by='NUTS_LABEL', aggfunc='mean').reset_index().rename({'400m': '400m_mean', '800m': '800m_mean'}, axis=1)\n",
    "\n",
    "#juntar\n",
    "raio_nut = raio_nut.merge(raio_mean.drop(columns=['geometry']), on='NUTS_LABEL')\n",
    "raio_nut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (g12, g13) = pp.subplots(nrows=1, ncols=2, figsize=(20, 16))\n",
    "#fig, (g10, g11, g12, g13) = pp.subplots(nrows=1, ncols=4, figsize=(20, 16))\n",
    "pp.tight_layout()\n",
    "\n",
    "#grafico10 = raio_nut.plot(ax=g10, column='400m', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "#grafico11 = raio_nut.plot(ax=g11, column='800m', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico12 = raio_nut.plot(ax=g12, column='400m_mean', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico13 = raio_nut.plot(ax=g13, column='800m_mean', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "\n",
    "grafico12.set_axis_off()\n",
    "grafico13.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1></h1>\n",
    "<h1>OBJECTIVO 3</h1>\n",
    "<h2>Determinar se a localização dos EFF apresenta depêndencia espacial da localização das escolas (ou seja, se os EFFs exibem um padrão de clustering em redor das escolas)</h2>\n",
    "\n",
    "- random mcd, bk e tel dentro dos buffers das vilas?\n",
    "- ver se ha aleatoriedade ou se há tendendecia de clustering em volta das escolas estatisticamente significativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kcross inohomgenous nao executval no python? Tive que exportar para R\n",
    "extraí as \"coordenadas\" da geometria para celulas à parte\n",
    "exportei para shapefile\n",
    "converti em ppp no R (ver https://github.com/jlevente/publications/blob/master/cross-k/calc_crossk.R)\n",
    "\n",
    "fiz a Kcross inhomegenous com envelope:\n",
    "    raio 1500m\n",
    "    lambdaX = vilas_ppm (para ter em consideração a maior probabilidade de calhar junto a vilas)\n",
    "    nrank=1 (para definir como min e max do envelope o n-esimo valor mínimo e o nésimo valor maximo\n",
    "    global = TRUE (para homegenizar as curvas e dar um uma probabilidade?)\n",
    "    correction='translation' (? resulta!)\n",
    "\n",
    "<s>Fiz exactamente o mesmo, mas com Lcross inhomegenous, pois esta permite ter um gráfico mais facilmente interpretavel (pois tem menor variação com o r?)\n",
    "Acrescentei na expressao do gráfico \".-r ~ r\", para que a recta da H0 fosse horizontal (e não diagonal)</s>\n",
    "\n",
    "Queria acrescentar as urbanas à heterogeneidade, mas sendo polígonos torna-se complicado.\n",
    "Nao consigo misturar poligonos com pontos, pois ha infinitos pontos dentro de um poligono e vou distorcer a intensidade\n",
    "\n",
    "Como tal, vou criar 2 analises de K functions: \n",
    "    uma fora das zonas urbanas, window = portugal - urbanas. tenho de retirar todos os pontos dentro das areas urbanas e so considerar os outros (atencao à aresta!!)\n",
    "    a outra dentro das areas urbanas, em que window = urbanas\n",
    "\n",
    "\n",
    "ver se faz diferença usar na intesnidade (lambdaX) o ppm ou a density\n",
    "\n",
    "falta saber como fazer cloropeth disto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocar na mesma dataframe as escolas e os restaurantes para poder passar a ppp. \n",
    "# Note-se que é necessário fazer a distinção entre os dois tipos de ponto de cada dataframe resultante, pelo que\n",
    "# é necessário acrescentar o tipo para poder fazer a distincao dos pontos escolas vs restaurante no R na funcao ppp\n",
    "\n",
    "temp_escolas = escolas.drop(columns=['Lat', 'Lon'])\n",
    "temp_escolas.insert(loc=0, column='Tipo', value='escola')\n",
    "\n",
    "# bk, mcd, tel\n",
    "uniao_escolas_bk = pandas.concat([bk.drop(columns=['Lat', 'Lon']), temp_escolas], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)\n",
    "uniao_escolas_mcd = pandas.concat([mcd.drop(columns=['Lat', 'Lon']), temp_escolas], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)\n",
    "uniao_escolas_tel = pandas.concat([tel.drop(columns=['Lat', 'Lon']), temp_escolas], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)\n",
    "\n",
    "# para os restaurantes no geral\n",
    "# Note-se que aqui é preciso acrescentar o tipo da variável restaurante, para distinguir das escolas, e aqui\n",
    "# já não importa a distinção entre diferentes tipos de restaurante\n",
    "\n",
    "temp_rest = rest.drop(columns=['Tipo','Lat', 'Lon'])\n",
    "temp_rest.insert(loc=0, column ='Tipo', value='restaurante')\n",
    "uniao_escolas_rest = pandas.concat([temp_rest, temp_escolas], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniao_escolas_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar que tantos os restaurantes, como as escolas como as vilas ou estão dentro ou fora das areas urbanas, \n",
    "#de forma a não perder os que poderiam estar nas bordas\n",
    "\n",
    "for a in (vilas, uniao_escolas_bk, uniao_escolas_mcd, uniao_escolas_tel, uniao_escolas_rest):\n",
    "    print(len(a[a.within(urbanas_poligono)]) + len(a[a.disjoint(urbanas_poligono)]) == len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separar dentro das areas urbanas vs fora\n",
    "uniao_escolas_rest_urbanas = uniao_escolas_rest[uniao_escolas_rest.within(urbanas_poligono)]\n",
    "uniao_escolas_rest_rural = uniao_escolas_rest[uniao_escolas_rest.disjoint(urbanas_poligono)]\n",
    "\n",
    "vilas_urbanas = vilas[vilas.within(urbanas_poligono)]\n",
    "vilas_rural = vilas[vilas.disjoint(urbanas_poligono)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extração das coordenadas x e y da geometria dos pontos (note-se que estão em CRS diferente das lat e lon originais!)\n",
    "\n",
    "def extrair_xy(lista):\n",
    "    x = [x for x,y in zip(lista['geometry'].x, lista['geometry'].y)]\n",
    "    y = [y for x,y in zip(lista['geometry'].x, lista['geometry'].y)]\n",
    "    lista.insert(loc=len(lista.columns), column='x', value=x)\n",
    "    lista.insert(loc=len(lista.columns), column='y', value=y)\n",
    "    \n",
    "extrair_xy(uniao_escolas_bk)\n",
    "extrair_xy(uniao_escolas_mcd)\n",
    "extrair_xy(uniao_escolas_tel)\n",
    "\n",
    "extrair_xy(vilas_urbanas)\n",
    "extrair_xy(vilas_rural)\n",
    "extrair_xy(uniao_escolas_rest_urbanas)\n",
    "extrair_xy(uniao_escolas_rest_rural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt_sem_urbanas\n",
    "rural = portugal[:][['NUTS_LABEL','geometry']]\n",
    "rural['geometry'] = portugal.difference(urbanas_poligono)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar para shapefile a ser lida n R\n",
    "portugal[['NUTS_LABEL', 'geometry']].to_file('shapefiles/portugal.shp', driver='ESRI Shapefile')\n",
    "rural.to_file('shapefiles/rural.shp', driver='ESRI Shapefile')\n",
    "urbanas.to_file('shapefiles/urbanas.shp', driver='ESRI Shapefile')\n",
    "\n",
    "vilas_urbanas.to_file('shapefiles/vilas_urbanas.shp', driver='ESRI Shapefile')\n",
    "vilas_rural.to_file('shapefiles/vilas_rural.shp', driver='ESRI Shapefile')\n",
    "\n",
    "uniao_escolas_bk.to_file('shapefiles/bk.shp', driver='ESRI Shapefile')\n",
    "uniao_escolas_mcd.to_file('shapefiles/mcd.shp', driver='ESRI Shapefile')\n",
    "uniao_escolas_tel.to_file('shapefiles/tel.shp', driver='ESRI Shapefile')\n",
    "uniao_escolas_rest.to_file('shapefiles/rest.shp', driver='ESRI Shapefile')\n",
    "uniao_escolas_rest_rural.to_file('shapefiles/rest_rural.shp', driver='ESRI Shapefile')\n",
    "uniao_escolas_rest_urbanas.to_file('shapefiles/rest_urbanas.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
