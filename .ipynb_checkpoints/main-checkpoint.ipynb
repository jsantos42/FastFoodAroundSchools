{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "#%matplotlib  inline\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy\n",
    "import pandas\n",
    "import geopandas as gp\n",
    "import csv\n",
    "import shapely.geometry\n",
    "import mapclassify\n",
    "import ipywidgets\n",
    "import ipympl\n",
    "\n",
    "pandas.options.display.max_rows = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the geodataframe from the shapefile and converting to the standard Coordinate \n",
    "# Reference System (CRS) of Portugal \n",
    "\n",
    "def read_shp(path):\n",
    "    gdf = gp.read_file(path, index = False)\n",
    "    gdf = gdf.to_crs(epsg = 3763)\n",
    "    return (gdf)\n",
    "\n",
    "portugal_gdf = read_shp('portugal_map_shapefile/DATA/Countries/PT/NUTS_3.shp')\n",
    "urban_gdf = read_shp('portugal_map_shapefile/DATA/Countries/PT/BuiltupA.shp')\n",
    "villages_gdf = read_shp('portugal_map_shapefile/DATA/Countries/PT/BuiltupP.shp')\n",
    "\n",
    "# Excluding Azores and Madeira, since this study focuses in mainland Portugal; note that\n",
    "# 'intersects' is a better choice than 'within' in the case of 'urban', because part of its \n",
    "# polygons overflow the 'portugal' ones\n",
    "azores = portugal_gdf[(portugal_gdf['NUTS_LABEL'] == 'Região Autónoma dos Açores')].index\n",
    "madeira = portugal_gdf[(portugal_gdf['NUTS_LABEL'] == 'Região Autónoma da Madeira')].index\n",
    "portugal = portugal_gdf.drop(azores.union(madeira))\n",
    "portugal_polygon = portugal.unary_union\n",
    "urban = urban_gdf[urban_gdf['geometry'].intersects(portugal_polygon) == True]\n",
    "villages = villages_gdf[villages_gdf['geometry'].within(portugal_polygon) == True]\n",
    "\n",
    "# Keeping only the relevant information\n",
    "urban = urban[['geometry']]\n",
    "villages = villages[['NAMA1', 'geometry']].rename({'NAMA1':'Nome'}, axis = 1)\n",
    "\n",
    "# Unifying all polygons of urban; this will be useful to check which POI are within 'urban'\n",
    "urban_polygon = urban.unary_union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting raw data from csv files, converting the coordinates to geometric points, building\n",
    "# geodataframes and converting to the standard CRS of Portugal; note that the CRS of the raw \n",
    "# data differs from the standard one, and this must be taken into account when importing\n",
    "\n",
    "def csv_to_gdf(path):\n",
    "    raw = pandas.read_csv(path, sep = ';', index_col = False)\n",
    "    geo = [Point(xy) for xy in zip(raw['Lon'], raw['Lat'])]\n",
    "    gdf = gp.GeoDataFrame(raw, geometry = geo, crs='epsg:4258')\n",
    "    crs = gdf.to_crs(epsg=3763)\n",
    "    return (crs)\n",
    "    \n",
    "bk_crs = csv_to_gdf('points_of_interest/burger_king.csv')\n",
    "mcd_crs = csv_to_gdf('points_of_interest/mcdonalds.csv')\n",
    "tel_crs = csv_to_gdf('points_of_interest/telepizza.csv')\n",
    "schools_crs = csv_to_gdf('points_of_interest/schools.csv')\n",
    "\n",
    "\n",
    "# Test for points outside Portugal (not needed anymore)\n",
    "#bk_crs[bk_crs['geometry'].within(portugal_polygon) == False]\n",
    "#mcd_crs[mcd_crs['geometry'].within(portugal_polygon) == False]\n",
    "#schools_crs[schools_crs['geometry'].within(portugal_polygon) == False]\n",
    "#tel_crs[tel_crs['geometry'].within(portugal_polygon) == False]\n",
    "\n",
    "# This could be used to check for duplicated school coordinates; in this case, it's not relevant,\n",
    "# since we know our database does contain cases of different schools with different levels of\n",
    "# education that have different names, and yet share the same building/area.\n",
    "#schools[schools['geometry'].duplicated(keep=False)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the corresponding NUT to the schools and restaurants GeoDataFrames. Note that the \n",
    "# following operation can only stores one geometry, and since we need to store the geometry\n",
    "# of the points (and not of the NUTs polygons), the reference has to be 'right'\n",
    "\n",
    "def adding_nut(original_variable):\n",
    "    joined = gp.sjoin(portugal, original_variable, predicate='contains', how='right')\n",
    "    if original_variable is schools_crs:\n",
    "        relevant_info = joined[['Nome', 'Lat', 'Lon','NUTS_LABEL', 'geometry']]\n",
    "    else:\n",
    "        relevant_info = joined[['Tipo','Nome', 'Lat', 'Lon','NUTS_LABEL', 'geometry']]\n",
    "    reordered = relevant_info.sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "    return (reordered)\n",
    "\n",
    "bk = adding_nut(bk_crs)\n",
    "mcd = adding_nut(mcd_crs)\n",
    "tel = adding_nut(tel_crs)\n",
    "schools = adding_nut(schools_crs)\n",
    "\n",
    "# Grouping the 3 restaurants brands in a single variable\n",
    "rest = pandas.concat([bk, mcd, tel], ignore_index=True)\n",
    "rest = rest.sort_values(by='NUTS_LABEL').reset_index(drop=True)\n",
    "\n",
    "# Aggregating schools and restaurants according to NUT, so to make choropleth maps. Note that\n",
    "# here the reference has to be 'left', since we need the geometry of the NUTs polygons\n",
    "def join_by_nut(original_variable):\n",
    "    joined = gp.sjoin(portugal, original_variable, predicate='contains', how='left')\n",
    "    relevant_info = joined[['Nome', 'NUTS_LABEL', 'geometry']]\n",
    "    per_nut = relevant_info.dissolve(by='NUTS_LABEL', aggfunc='count')\n",
    "    reordered = per_nut.reset_index().rename({'Nome': 'count'}, axis=1)\n",
    "    return (reordered)\n",
    "\n",
    "schools_nut = join_by_nut(schools_crs)\n",
    "bk_nut = join_by_nut(bk_crs)\n",
    "mcd_nut = join_by_nut(mcd_crs)\n",
    "tel_nut = join_by_nut(tel_crs)\n",
    "rest_nut = join_by_nut(rest.drop(columns='NUTS_LABEL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the schools and restaurants in mainland Portugal\n",
    "\n",
    "def interactive_plot():\n",
    "    fig, ax = pyplot.subplots(figsize=(8,10))\n",
    "    fig.set_facecolor((1,1,1))\n",
    "    ax.set_axis_off()\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.95, right=0.85)\n",
    "    fig.suptitle('Nationwide Distribution of Schools \\nand the 3 Major Fast-Food Brands',\n",
    "                 va='top', fontsize=15, fontweight='bold')\n",
    "\n",
    "    portugal.plot(ax=ax, edgecolor='k', alpha= 0.7, facecolor='white')\n",
    "    villages.plot(ax=ax, edgecolor='black', alpha=0.5, facecolor='none', label='Villages')\n",
    "    schools.plot(ax=ax, color='blue', alpha=0.4, markersize=5, label='Schools')\n",
    "    bk.plot(ax=ax, color='red', alpha= 0.3, markersize=5, label ='Burger King')\n",
    "    mcd.plot(ax=ax, color='red', alpha=0.3, markersize=5, label = 'McDonalds')\n",
    "    tel.plot(ax=ax, color='red', alpha= 0.3, markersize=5, label = 'Telepizza')\n",
    "    urban.plot(ax=ax, color='black', alpha=0.2)\n",
    "    \n",
    "    # Not all handles can be turned into legend entries automatically, so it is often necessary\n",
    "    # to create an artist which can; in this case, 'urban' has no legend in the map\n",
    "    # from: https://matplotlib.org/tutorials/intermediate/legend_guide.html\n",
    "\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 0.5), fontsize=13, borderaxespad=0)\n",
    "    scalebar = ScaleBar(dx=1, \n",
    "                        length_fraction=0.4, \n",
    "                        location='lower right', \n",
    "                        color='black',\n",
    "                        sep=7,\n",
    "                        pad=0,\n",
    "                        border_pad=0)\n",
    "    pyplot.gca().add_artist(scalebar)\n",
    "    leg = interactive_legend()\n",
    "    return fig, ax, leg\n",
    "\n",
    "# The following functions were taken from an answer on SOF (kudos to ImportanceofBeingErnest and\n",
    "# Joe Kington) \n",
    "# from: https://stackoverflow.com/questions/31410043/hiding-lines-after-showing-a-pyplot-figure\n",
    "\n",
    "def interactive_legend(ax=None):\n",
    "    if ax is None:\n",
    "        ax = pyplot.gca()\n",
    "    if ax.legend_ is None:\n",
    "        ax.legend()\n",
    "\n",
    "    return InteractiveLegend(ax.get_legend())\n",
    "\n",
    "class InteractiveLegend(object):\n",
    "    def __init__(self, legend):\n",
    "        self.legend = legend\n",
    "        self.fig = legend.axes.figure\n",
    "\n",
    "        self.lookup_artist, self.lookup_handle = self._build_lookups(legend)\n",
    "        self._setup_connections()\n",
    "\n",
    "        self.update()\n",
    "\n",
    "    def _setup_connections(self):\n",
    "        for artist in self.legend.texts + self.legend.legendHandles:\n",
    "            artist.set_picker(10) # 10 points tolerance\n",
    "\n",
    "        self.fig.canvas.mpl_connect('pick_event', self.on_pick)\n",
    "        self.fig.canvas.mpl_connect('button_press_event', self.on_click)\n",
    "\n",
    "    def _build_lookups(self, legend):\n",
    "        labels = [t.get_text() for t in legend.texts]\n",
    "        handles = legend.legendHandles\n",
    "        label2handle = dict(zip(labels, handles))\n",
    "        handle2text = dict(zip(handles, legend.texts))\n",
    "\n",
    "        lookup_artist = {}\n",
    "        lookup_handle = {}\n",
    "        for artist in legend.axes.get_children():\n",
    "            if artist.get_label() in labels:\n",
    "                handle = label2handle[artist.get_label()]\n",
    "                lookup_handle[artist] = handle\n",
    "                lookup_artist[handle] = artist\n",
    "                lookup_artist[handle2text[handle]] = artist\n",
    "\n",
    "        lookup_handle.update(zip(handles, handles))\n",
    "        lookup_handle.update(zip(legend.texts, handles))\n",
    "\n",
    "        return lookup_artist, lookup_handle\n",
    "\n",
    "    def on_pick(self, event):\n",
    "        handle = event.artist\n",
    "        if handle in self.lookup_artist:\n",
    "\n",
    "            artist = self.lookup_artist[handle]\n",
    "            artist.set_visible(not artist.get_visible())\n",
    "            self.update()\n",
    "\n",
    "    def on_click(self, event):\n",
    "        if event.button == 3:\n",
    "            visible = False\n",
    "        elif event.button == 2:\n",
    "            visible = True\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        for artist in self.lookup_artist.values():\n",
    "            artist.set_visible(visible)\n",
    "        self.update()\n",
    "\n",
    "    def update(self):\n",
    "        for artist in self.lookup_artist.values():\n",
    "            handle = self.lookup_handle[artist]\n",
    "            if artist.get_visible():\n",
    "                handle.set_visible(True)\n",
    "            else:\n",
    "                handle.set_visible(False)\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def show(self):\n",
    "        pyplot.show()\n",
    "\n",
    "fig, ax, leg = interactive_plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribuiçao nacional das schools e de cada restaurante, por NUT\n",
    "fig, (g2, g3, g4, g5, g6) = pyplot.subplots(nrows=1, ncols=5, figsize=(20, 16))\n",
    "pyplot.tight_layout()\n",
    "\n",
    "grafico2 = schools_nut.plot(ax=g2, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico3 = bk_nut.plot(ax=g3, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico4 = mcd_nut.plot(ax=g4, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico5 = tel_nut.plot(ax=g5, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico6 = rest_nut.plot(ax=g6, column='count', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1></h1>\n",
    "<h1>OBJECTIVO 1</h1>\n",
    "<h2>Determinar, para cada escola em Portugal continental, qual a proximidade ao estabelecimento de fast-food (EFF) mais próximo</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mudei os nomes das entradas para Capitalized\n",
    "#acrescentei o tipo de rest nos csv dos mcd e tel\n",
    "#padronizei os labels das colunas\n",
    "#comparei visualmente no mapa para ver se batia certo\n",
    "\n",
    "\n",
    "#retirado de https://gis.stackexchange.com/questions/222315/geopandas-find-nearest-point-in-other-dataframe\n",
    "\n",
    "def ckdnearest(gdA, gdB):\n",
    "    nA = numpy.array(list(gdA.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    nB = numpy.array(list(gdB.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    btree = cKDTree(nB)\n",
    "    dist, idx = btree.query(nA, k=1)\n",
    "    gdf = pandas.concat(\n",
    "        [gdA.reset_index(drop=True), gdB.loc[idx, gdB.columns != 'geometry'].reset_index(drop=True),\n",
    "         pandas.Series(dist, name='dist')], axis=1)\n",
    "    gdf['dist'] = gdf['dist'] / 1000  #conversao de m para km\n",
    "    return gdf\n",
    "\n",
    "prox = ckdnearest(schools.drop(columns=['Lat', 'Lon']).rename({'Nome':'ESCOLA'}, axis =1), rest.drop(columns=['Lat', 'Lon', 'NUTS_LABEL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar schools e restaurantes por NUT para poder fazer choropleth\n",
    "# criar as estatisticas por NUTs\n",
    "\n",
    "prox_mean = geopandas.sjoin(portugal, prox.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','ESCOLA','Nome','dist']].dissolve(by='NUTS_LABEL', aggfunc='mean').reset_index().rename({'dist': 'mean'}, axis=1)\n",
    "prox_median = geopandas.sjoin(portugal, prox.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','ESCOLA','Nome','dist']].dissolve(by='NUTS_LABEL', aggfunc='median').reset_index().rename({'dist': 'median'}, axis=1)\n",
    "prox_min = geopandas.sjoin(portugal, prox.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','dist']].dissolve(by='NUTS_LABEL', aggfunc='min').reset_index().rename({'dist': 'min'}, axis=1)\n",
    "prox_max = geopandas.sjoin(portugal, prox.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','dist']].dissolve(by='NUTS_LABEL', aggfunc='max').reset_index().rename({'dist': 'max'}, axis=1)\n",
    "\n",
    "prox_nut = prox_mean.merge(prox_min.drop(columns='geometry'), on='NUTS_LABEL').merge(prox_median.drop(columns='geometry'), on='NUTS_LABEL').merge(prox_max.drop(columns='geometry'), on='NUTS_LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_nut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipywidgets.interact\n",
    "def show_articles_more_than(column=['median', 'min'], x=(0, 35, 1)):\n",
    "    return prox_nut.loc[prox_nut[column] < x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, (g7, g8, g9) = pyplot.subplots(nrows=1, ncols=3, figsize=(20, 16))\n",
    "#usamos a mediana pois ha outliers\n",
    "pyplot.tight_layout()\n",
    "\n",
    "grafico7 = prox_nut.plot(column='median', figsize=(20,16), legend=True, scheme='FisherJenks', cmap='Greens_r', edgecolor='k')\n",
    "grafico7.set_axis_off()\n",
    "#grafico8 = prox_nut.plot(ax=g8, column='min', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens_r', edgecolor='k')\n",
    "#grafico9 = prox_nut.plot(ax=g9, column='max', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens_r', edgecolor='k')\n",
    "#fig.canvas.toolbar_visible = False\n",
    "#fig.canvas.header_visible = False\n",
    "#fig.canvas.resizable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.distplot(prox_nut['min'], rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1></h1>\n",
    "<h1>OBJECTIVO 2</h1>\n",
    "<h2>Determinar, para cada escola em Portugal continental, quantos EFF estão a curta distância (raios de 5 e de 10min a pé)</h2>\n",
    "<h1>SEEMS TO BE WORKING UNTIL HERE</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada escola, criar um raio de 400m e de 800m e contar quantos rest estão nesse círculos\n",
    "i = 0\n",
    "raio = schools[:]  # slice op para copiar o conteúdo e não linkar à variável antiga\n",
    "raio['400m'] = ''  # criar novas duas colunas vazias\n",
    "raio['800m'] = ''\n",
    "\n",
    "for i in range(len(schools)):\n",
    "    raio.loc[i,'400m'] = len(rest[rest['geometry'].within(schools['geometry'][i].buffer(400))])\n",
    "    raio.loc[i,'800m'] = len(rest[rest['geometry'].within(schools['geometry'][i].buffer(800))])\n",
    "\n",
    "raio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar dados raio por NUT para poder fazer choropleth\n",
    "# soma\n",
    "raio_nut = geopandas.sjoin(portugal, raio.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','Nome','400m','800m']].dissolve(by='NUTS_LABEL', aggfunc='sum').reset_index()\n",
    "\n",
    "\n",
    "# média de restaurantes no raio especificado para as schools de cada NUT\n",
    "raio_mean = geopandas.sjoin(portugal, raio.drop(columns=['NUTS_LABEL']), predicate='contains', how='left')[['NUTS_LABEL','geometry','400m','800m']]\n",
    "raio_mean[['400m', '800m']] = raio_mean[['400m', '800m']].apply(pandas.to_numeric) # por algum motivo que desconheço, estas colunas aparecem como objectos e impossibilitam a obtenção da média, pelo que tenho de converter em números\n",
    "raio_mean = raio_mean.dissolve(by='NUTS_LABEL', aggfunc='mean').reset_index().rename({'400m': '400m_mean', '800m': '800m_mean'}, axis=1)\n",
    "\n",
    "#juntar\n",
    "raio_nut = raio_nut.merge(raio_mean.drop(columns=['geometry']), on='NUTS_LABEL')\n",
    "raio_nut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (g12, g13) = pp.subplots(nrows=1, ncols=2, figsize=(20, 16))\n",
    "#fig, (g10, g11, g12, g13) = pp.subplots(nrows=1, ncols=4, figsize=(20, 16))\n",
    "pp.tight_layout()\n",
    "\n",
    "#grafico10 = raio_nut.plot(ax=g10, column='400m', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "#grafico11 = raio_nut.plot(ax=g11, column='800m', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico12 = raio_nut.plot(ax=g12, column='400m_mean', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "grafico13 = raio_nut.plot(ax=g13, column='800m_mean', figsize=(5,5), legend=True, scheme='FisherJenks', cmap='Greens', edgecolor='k')\n",
    "\n",
    "grafico12.set_axis_off()\n",
    "grafico13.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1></h1>\n",
    "<h1>OBJECTIVO 3</h1>\n",
    "<h2>Determinar se a localização dos EFF apresenta depêndencia espacial da localização das schools (ou seja, se os EFFs exibem um padrão de clustering em redor das schools)</h2>\n",
    "\n",
    "- random mcd, bk e tel dentro dos buffers das villages?\n",
    "- ver se ha aleatoriedade ou se há tendendecia de clustering em volta das schools estatisticamente significativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kcross inohomgenous nao executval no python? Tive que exportar para R\n",
    "extraí as \"coordenadas\" da geometria para celulas à parte\n",
    "exportei para shapefile\n",
    "converti em ppp no R (ver https://github.com/jlevente/publications/blob/master/cross-k/calc_crossk.R)\n",
    "\n",
    "fiz a Kcross inhomegenous com envelope:\n",
    "    raio 1500m\n",
    "    lambdaX = villages_ppm (para ter em consideração a maior probabilidade de calhar junto a vilas)\n",
    "    nrank=1 (para definir como min e max do envelope o n-esimo valor mínimo e o nésimo valor maximo\n",
    "    global = TRUE (para homegenizar as curvas e dar um uma probabilidade?)\n",
    "    correction='translation' (? resulta!)\n",
    "\n",
    "<s>Fiz exactamente o mesmo, mas com Lcross inhomegenous, pois esta permite ter um gráfico mais facilmente interpretavel (pois tem menor variação com o r?)\n",
    "Acrescentei na expressao do gráfico \".-r ~ r\", para que a recta da H0 fosse horizontal (e não diagonal)</s>\n",
    "\n",
    "Queria acrescentar as urban à heterogeneidade, mas sendo polígonos torna-se complicado.\n",
    "Nao consigo misturar polygons com pontos, pois ha infinitos pontos dentro de um polygon e vou distorcer a intensidade\n",
    "\n",
    "Como tal, vou criar 2 analises de K functions: \n",
    "    uma fora das zonas urban, window = portugal - urban. tenho de retirar todos os pontos dentro das areas urban e so considerar os outros (atencao à aresta!!)\n",
    "    a outra dentro das areas urban, em que window = urban\n",
    "\n",
    "\n",
    "ver se faz diferença usar na intesnidade (lambdaX) o ppm ou a density\n",
    "\n",
    "falta saber como fazer cloropeth disto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocar na mesma dataframe as schools e os restaurantes para poder passar a ppp. \n",
    "# Note-se que é necessário fazer a distinção entre os dois tipos de ponto de cada dataframe resultante, pelo que\n",
    "# é necessário acrescentar o tipo para poder fazer a distincao dos pontos schools vs restaurante no R na funcao ppp\n",
    "\n",
    "temp_schools = schools.drop(columns=['Lat', 'Lon'])\n",
    "temp_schools.insert(loc=0, column='Tipo', value='escola')\n",
    "\n",
    "# bk, mcd, tel\n",
    "uniao_schools_bk = pandas.concat([bk.drop(columns=['Lat', 'Lon']), temp_schools], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)\n",
    "uniao_schools_mcd = pandas.concat([mcd.drop(columns=['Lat', 'Lon']), temp_schools], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)\n",
    "uniao_schools_tel = pandas.concat([tel.drop(columns=['Lat', 'Lon']), temp_schools], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)\n",
    "\n",
    "# para os restaurantes no geral\n",
    "# Note-se que aqui é preciso acrescentar o tipo da variável restaurante, para distinguir das schools, e aqui\n",
    "# já não importa a distinção entre diferentes tipos de restaurante\n",
    "\n",
    "temp_rest = rest.drop(columns=['Tipo','Lat', 'Lon'])\n",
    "temp_rest.insert(loc=0, column ='Tipo', value='restaurante')\n",
    "uniao_schools_rest = pandas.concat([temp_rest, temp_schools], ignore_index=True).sort_values(by='Tipo').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniao_schools_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificar que tantos os restaurantes, como as schools como as villages ou estão dentro ou fora das areas urban, \n",
    "#de forma a não perder os que poderiam estar nas bordas\n",
    "\n",
    "for a in (villages, uniao_schools_bk, uniao_schools_mcd, uniao_schools_tel, uniao_schools_rest):\n",
    "    print(len(a[a.within(urban_polygon)]) + len(a[a.disjoint(urban_polygon)]) == len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separar dentro das areas urban vs fora\n",
    "uniao_schools_rest_urban = uniao_schools_rest[uniao_schools_rest.within(urban_polygon)]\n",
    "uniao_schools_rest_rural = uniao_schools_rest[uniao_schools_rest.disjoint(urban_polygon)]\n",
    "\n",
    "villages_urban = vilas[vilas.within(urban_polygon)]\n",
    "villages_rural = vilas[vilas.disjoint(urban_polygon)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extração das coordenadas x e y da geometria dos pontos (note-se que estão em CRS diferente das lat e lon originais!)\n",
    "\n",
    "def extrair_xy(lista):\n",
    "    x = [x for x,y in zip(lista['geometry'].x, lista['geometry'].y)]\n",
    "    y = [y for x,y in zip(lista['geometry'].x, lista['geometry'].y)]\n",
    "    lista.insert(loc=len(lista.columns), column='x', value=x)\n",
    "    lista.insert(loc=len(lista.columns), column='y', value=y)\n",
    "    \n",
    "extrair_xy(uniao_schools_bk)\n",
    "extrair_xy(uniao_schools_mcd)\n",
    "extrair_xy(uniao_schools_tel)\n",
    "\n",
    "extrair_xy(villages_urban)\n",
    "extrair_xy(villages_rural)\n",
    "extrair_xy(uniao_schools_rest_urban)\n",
    "extrair_xy(uniao_schools_rest_rural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt_sem_urban\n",
    "rural = portugal[:][['NUTS_LABEL','geometry']]\n",
    "rural['geometry'] = portugal.difference(urban_polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar para shapefile a ser lida n R\n",
    "portugal[['NUTS_LABEL', 'geometry']].to_file('shapefiles/portugal.shp', driver='ESRI Shapefile')\n",
    "rural.to_file('shapefiles/rural.shp', driver='ESRI Shapefile')\n",
    "urban.to_file('shapefiles/urban.shp', driver='ESRI Shapefile')\n",
    "\n",
    "villages_urban.to_file('shapefiles/vilas_urban.shp', driver='ESRI Shapefile')\n",
    "villages_rural.to_file('shapefiles/vilas_rural.shp', driver='ESRI Shapefile')\n",
    "\n",
    "uniao_schools_bk.to_file('shapefiles/bk.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_mcd.to_file('shapefiles/mcd.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_tel.to_file('shapefiles/tel.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_rest.to_file('shapefiles/rest.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_rest_rural.to_file('shapefiles/rest_rural.shp', driver='ESRI Shapefile')\n",
    "uniao_schools_rest_urban.to_file('shapefiles/rest_urban.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
